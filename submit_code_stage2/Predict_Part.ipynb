{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import sys\n",
    "import time \n",
    "import json \n",
    "import torch \n",
    "import random \n",
    "import warnings\n",
    "import torchvision\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "from utils import *\n",
    "from data import PlanetDataset\n",
    "from tqdm import tqdm\n",
    "from config_weightedce import config\n",
    "from datetime import datetime\n",
    "from models.model import *\n",
    "from torch import nn,optim\n",
    "from collections import OrderedDict\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import lr_scheduler\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test model on public dataset and save the probability matrix\n",
    "def test(test_loader, model, folds, all_train_loader=None):\n",
    "#     sample_submission_df = pd.read_csv(\"./dataset/test_visit.csv\")\n",
    "    #3.1 confirm the model converted to cuda\n",
    "    filenames, labels_te, labels_tr, submissions= [],[],[],[]\n",
    "    labels_true = []\n",
    "    model.cuda()\n",
    "    model.eval()\n",
    "    submit_results = []\n",
    "    try:\n",
    "        if not isinstance(test_loader, type(None)):\n",
    "            with tqdm(test_loader, ascii = True) as t:\n",
    "                for img_data, visit_data, filepath in t:\n",
    "                    #3.2 change everything to cuda and get only basename\n",
    "                    filepath = [x for x in filepath]\n",
    "                    with torch.no_grad():\n",
    "                        image_var = img_data.cuda(non_blocking=True)\n",
    "                        visit_var = visit_data.cuda(non_blocking=True)\n",
    "                        y_pred = model(image_var, visit_var)\n",
    "                        label = y_pred.cpu().data.numpy()\n",
    "                        #print(label > 0.5)\n",
    "\n",
    "                        submit_results.append(np.argmax(label, 1))\n",
    "                        labels_te.append(np.squeeze(label))\n",
    "\n",
    "                        filenames.append(np.squeeze(filepath))\n",
    "\n",
    "        if not isinstance(all_train_loader, type(None)):\n",
    "            with tqdm(all_train_loader, ascii = True) as t:\n",
    "                for img_data, visit_data, target in t:\n",
    "                    #3.2 change everything to cuda and get only basename\n",
    "                    target = np.squeeze(target).cpu().data.numpy()\n",
    "                    with torch.no_grad():\n",
    "                        image_var = img_data.cuda(non_blocking=True)\n",
    "                        visit_var = visit_data.cuda(non_blocking=True)\n",
    "                        y_pred = model(image_var, visit_var)\n",
    "                        label = y_pred.cpu().data.numpy()\n",
    "                        labels_tr.append(np.hstack([np.squeeze(label), target.reshape(-1, 1)]))\n",
    "            return None, np.concatenate(labels_tr)#np.concatenate(labels_te)\n",
    "    except:\n",
    "        t.close()\n",
    "        raise\n",
    "    t.close()\n",
    "\n",
    "# \tsample_submission_df['Predicted'] = np.concatenate(submit_results)\n",
    "# \tsample_submission_df['IterId'] = np.concatenate(filenames)\n",
    "# \tsample_submission_df.to_csv('./submit/%s_bestloss_submission%s.csv'%(config.model_name, folds), index=None)\n",
    "    return np.concatenate(labels_te), None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test model on public dataset and save the probability matrix\n",
    "def test(test_loader, model, folds, all_train_loaders=None):\n",
    "#     sample_submission_df = pd.read_csv(\"./dataset/test_visit.csv\")\n",
    "    #3.1 confirm the model converted to cuda\n",
    "    [all_train_loader, b_train_loader] = all_train_loaders\n",
    "    \n",
    "    filenames, labels_te, labels_tr, labels_b, submissions= [],[],[],[], []\n",
    "    labels_true = []\n",
    "    model.cuda()\n",
    "    model.eval()\n",
    "    submit_results = []\n",
    "    try:\n",
    "        if not isinstance(test_loader, type(None)):\n",
    "            with tqdm(test_loader, ascii = True) as t:\n",
    "                for img_data, visit_data, filepath in t:\n",
    "                    #3.2 change everything to cuda and get only basename\n",
    "                    filepath = [x for x in filepath]\n",
    "                    with torch.no_grad():\n",
    "                        image_var = img_data.cuda(non_blocking=True)\n",
    "                        visit_var = visit_data.cuda(non_blocking=True)\n",
    "                        y_pred = model(image_var, visit_var)\n",
    "                        label = y_pred.cpu().data.numpy()\n",
    "                        #print(label > 0.5)\n",
    "\n",
    "                        submit_results.append(np.argmax(label, 1))\n",
    "                        labels_te.append(np.squeeze(label))\n",
    "\n",
    "                        filenames.append(np.squeeze(filepath))\n",
    "\n",
    "        if not isinstance(all_train_loader, type(None)):\n",
    "            with tqdm(all_train_loader, ascii = True) as t:\n",
    "                for img_data, visit_data, target in t:\n",
    "                    #3.2 change everything to cuda and get only basename\n",
    "#                     return target\n",
    "                    target = np.squeeze(target).cpu().data.numpy()\n",
    "                    with torch.no_grad():\n",
    "                        image_var = img_data.cuda(non_blocking=True)\n",
    "                        visit_var = visit_data.cuda(non_blocking=True)\n",
    "                        y_pred = model(image_var, visit_var)\n",
    "                        label = y_pred.cpu().data.numpy()\n",
    "                        labels_tr.append(np.hstack([np.squeeze(label), target.reshape(-1, 1)]))\n",
    "            with tqdm(b_train_loader, ascii = True) as t:\n",
    "                for img_data, visit_data, target in t:\n",
    "                    #3.2 change everything to cuda and get only basename\n",
    "#                     return target\n",
    "                    target = np.squeeze(target).cpu().data.numpy()\n",
    "                    with torch.no_grad():\n",
    "                        image_var = img_data.cuda(non_blocking=True)\n",
    "                        visit_var = visit_data.cuda(non_blocking=True)\n",
    "                        y_pred = model(image_var, visit_var)\n",
    "                        label = y_pred.cpu().data.numpy()\n",
    "                        labels_b.append(np.hstack([np.squeeze(label), target.reshape(-1, 1)]))\n",
    "            return np.concatenate(labels_te), np.concatenate(labels_tr), np.concatenate(labels_b)#np.concatenate(labels_te)\n",
    "    except:\n",
    "        t.close()\n",
    "        raise\n",
    "    t.close()\n",
    "\n",
    "# \tsample_submission_df['Predicted'] = np.concatenate(submit_results)\n",
    "# \tsample_submission_df['IterId'] = np.concatenate(filenames)\n",
    "# \tsample_submission_df.to_csv('./submit/%s_bestloss_submission%s.csv'%(config.model_name, folds), index=None)\n",
    "    return np.concatenate(labels_te), None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0, 1, 2, 3\"\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# config.model_name = \"seresnext5032x4d_resnet110-FLlog-03washing-vp-adjustlr-v0pretrained\"  # 7*24*26visit 的模型名称\n",
    "# config.model_name = \"seresnext5032x4d_resnet110-celog-03washing-182vp-adjustlr-skf\" # 24*182visit 的模型名称\n",
    "config.model_name = \"seresnext5032x4d_resnet110-CE-03washing-v0-segpre\"\n",
    "config.model_name = \"seresnext5032x4d_resnet110-CE-03washing-v0-imgpre\"#addcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# discriminator parameters: 27502793\n"
     ]
    }
   ],
   "source": [
    "print('# discriminator parameters:', sum(param.numel() for param in model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config.model_name = \"seresnext5032x4d-FLlog-03washing-lr28-v0-final-batch256\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config.model_name = \"resnet110-visituser-CElog-03washing-lr26-v0-final-nonorm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): MultiModalNet(\n",
       "    (image_model): SENet(\n",
       "      (layer0): Sequential(\n",
       "        (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (pool): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "      )\n",
       "      (layer1): Sequential(\n",
       "        (0): SEResNeXtBottleneck(\n",
       "          (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "          (se_module): SEModule(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): ReLU(inplace)\n",
       "            (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): SEResNeXtBottleneck(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "          (se_module): SEModule(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): ReLU(inplace)\n",
       "            (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (2): SEResNeXtBottleneck(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "          (se_module): SEModule(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): ReLU(inplace)\n",
       "            (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): SEResNeXtBottleneck(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "          (se_module): SEModule(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): ReLU(inplace)\n",
       "            (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): SEResNeXtBottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "          (se_module): SEModule(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): ReLU(inplace)\n",
       "            (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (2): SEResNeXtBottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "          (se_module): SEModule(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): ReLU(inplace)\n",
       "            (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (3): SEResNeXtBottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "          (se_module): SEModule(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): ReLU(inplace)\n",
       "            (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): SEResNeXtBottleneck(\n",
       "          (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "          (se_module): SEModule(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): ReLU(inplace)\n",
       "            (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): SEResNeXtBottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "          (se_module): SEModule(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): ReLU(inplace)\n",
       "            (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (2): SEResNeXtBottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "          (se_module): SEModule(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): ReLU(inplace)\n",
       "            (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (3): SEResNeXtBottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "          (se_module): SEModule(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): ReLU(inplace)\n",
       "            (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (4): SEResNeXtBottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "          (se_module): SEModule(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): ReLU(inplace)\n",
       "            (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (5): SEResNeXtBottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "          (se_module): SEModule(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): ReLU(inplace)\n",
       "            (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): SEResNeXtBottleneck(\n",
       "          (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "          (se_module): SEModule(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): ReLU(inplace)\n",
       "            (fc2): Conv2d(128, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): SEResNeXtBottleneck(\n",
       "          (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "          (se_module): SEModule(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): ReLU(inplace)\n",
       "            (fc2): Conv2d(128, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (2): SEResNeXtBottleneck(\n",
       "          (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "          (se_module): SEModule(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): ReLU(inplace)\n",
       "            (fc2): Conv2d(128, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "      (last_linear): Sequential(\n",
       "        (0): Linear(in_features=2048, out_features=128, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (visit_model): ResNet(\n",
       "      (conv1): Conv2d(7, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (layer1): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (shortcut): Sequential()\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (shortcut): Sequential()\n",
       "        )\n",
       "        (2): BasicBlock(\n",
       "          (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (shortcut): Sequential()\n",
       "        )\n",
       "        (3): BasicBlock(\n",
       "          (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (shortcut): Sequential()\n",
       "        )\n",
       "        (4): BasicBlock(\n",
       "          (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (shortcut): Sequential()\n",
       "        )\n",
       "        (5): BasicBlock(\n",
       "          (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (shortcut): Sequential()\n",
       "        )\n",
       "        (6): BasicBlock(\n",
       "          (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (shortcut): Sequential()\n",
       "        )\n",
       "        (7): BasicBlock(\n",
       "          (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (shortcut): Sequential()\n",
       "        )\n",
       "        (8): BasicBlock(\n",
       "          (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (shortcut): Sequential()\n",
       "        )\n",
       "        (9): BasicBlock(\n",
       "          (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (shortcut): Sequential()\n",
       "        )\n",
       "        (10): BasicBlock(\n",
       "          (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (shortcut): Sequential()\n",
       "        )\n",
       "        (11): BasicBlock(\n",
       "          (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (shortcut): Sequential()\n",
       "        )\n",
       "        (12): BasicBlock(\n",
       "          (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (shortcut): Sequential()\n",
       "        )\n",
       "        (13): BasicBlock(\n",
       "          (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (shortcut): Sequential()\n",
       "        )\n",
       "        (14): BasicBlock(\n",
       "          (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (shortcut): Sequential()\n",
       "        )\n",
       "        (15): BasicBlock(\n",
       "          (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (shortcut): Sequential()\n",
       "        )\n",
       "        (16): BasicBlock(\n",
       "          (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (shortcut): Sequential()\n",
       "        )\n",
       "        (17): BasicBlock(\n",
       "          (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (shortcut): Sequential()\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (shortcut): LambdaLayer()\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (shortcut): Sequential()\n",
       "        )\n",
       "        (2): BasicBlock(\n",
       "          (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (shortcut): Sequential()\n",
       "        )\n",
       "        (3): BasicBlock(\n",
       "          (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (shortcut): Sequential()\n",
       "        )\n",
       "        (4): BasicBlock(\n",
       "          (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (shortcut): Sequential()\n",
       "        )\n",
       "        (5): BasicBlock(\n",
       "          (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (shortcut): Sequential()\n",
       "        )\n",
       "        (6): BasicBlock(\n",
       "          (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (shortcut): Sequential()\n",
       "        )\n",
       "        (7): BasicBlock(\n",
       "          (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (shortcut): Sequential()\n",
       "        )\n",
       "        (8): BasicBlock(\n",
       "          (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (shortcut): Sequential()\n",
       "        )\n",
       "        (9): BasicBlock(\n",
       "          (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (shortcut): Sequential()\n",
       "        )\n",
       "        (10): BasicBlock(\n",
       "          (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (shortcut): Sequential()\n",
       "        )\n",
       "        (11): BasicBlock(\n",
       "          (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (shortcut): Sequential()\n",
       "        )\n",
       "        (12): BasicBlock(\n",
       "          (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (shortcut): Sequential()\n",
       "        )\n",
       "        (13): BasicBlock(\n",
       "          (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (shortcut): Sequential()\n",
       "        )\n",
       "        (14): BasicBlock(\n",
       "          (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (shortcut): Sequential()\n",
       "        )\n",
       "        (15): BasicBlock(\n",
       "          (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (shortcut): Sequential()\n",
       "        )\n",
       "        (16): BasicBlock(\n",
       "          (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (shortcut): Sequential()\n",
       "        )\n",
       "        (17): BasicBlock(\n",
       "          (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (shortcut): Sequential()\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (shortcut): LambdaLayer()\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (shortcut): Sequential()\n",
       "        )\n",
       "        (2): BasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (shortcut): Sequential()\n",
       "        )\n",
       "        (3): BasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (shortcut): Sequential()\n",
       "        )\n",
       "        (4): BasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (shortcut): Sequential()\n",
       "        )\n",
       "        (5): BasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (shortcut): Sequential()\n",
       "        )\n",
       "        (6): BasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (shortcut): Sequential()\n",
       "        )\n",
       "        (7): BasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (shortcut): Sequential()\n",
       "        )\n",
       "        (8): BasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (shortcut): Sequential()\n",
       "        )\n",
       "        (9): BasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (shortcut): Sequential()\n",
       "        )\n",
       "        (10): BasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (shortcut): Sequential()\n",
       "        )\n",
       "        (11): BasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (shortcut): Sequential()\n",
       "        )\n",
       "        (12): BasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (shortcut): Sequential()\n",
       "        )\n",
       "        (13): BasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (shortcut): Sequential()\n",
       "        )\n",
       "        (14): BasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (shortcut): Sequential()\n",
       "        )\n",
       "        (15): BasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (shortcut): Sequential()\n",
       "        )\n",
       "        (16): BasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (shortcut): Sequential()\n",
       "        )\n",
       "        (17): BasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (shortcut): Sequential()\n",
       "        )\n",
       "      )\n",
       "      (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "      (last_linear): Dropout(p=0)\n",
       "      (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "    )\n",
       "    (cls): Sequential(\n",
       "      (0): Dropout(p=0.05)\n",
       "      (1): Linear(in_features=192, out_features=9, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold  0\n",
      "train seresnext5032x4d\n",
      "train resnet110\n",
      "Single model pretrained respectively\n",
      "=> loading checkpoint './checkpoints/best_models//seresnext5032x4d-img224-FLlog-03washing-lr28-v0-final-batch32_fold_0_model_best_loss.pth.tar'\n",
      "Modifing model...\n",
      "Let's use 4 GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##################################################################################| 98/98 [03:56<00:00, 18.17s/it]\n",
      "100%|##################################################################################| 78/78 [03:12<00:00, 21.21s/it]\n",
      "100%|####################################################################################| 2/2 [01:26<00:00, 48.08s/it]\n",
      "100%|##################################################################################| 98/98 [02:14<00:00,  1.55it/s]\n",
      "100%|##################################################################################| 78/78 [01:53<00:00,  1.48it/s]\n",
      "100%|####################################################################################| 2/2 [00:48<00:00, 33.93s/it]\n",
      "100%|##################################################################################| 98/98 [02:09<00:00,  1.53it/s]\n",
      "100%|##################################################################################| 78/78 [01:54<00:00,  1.51it/s]\n",
      "100%|####################################################################################| 2/2 [00:49<00:00, 34.23s/it]\n",
      "100%|##################################################################################| 98/98 [02:11<00:00,  1.52it/s]\n",
      "100%|##################################################################################| 78/78 [02:00<00:00,  1.48it/s]\n",
      "100%|####################################################################################| 2/2 [00:53<00:00, 37.49s/it]\n",
      "100%|##################################################################################| 98/98 [02:13<00:00,  1.51it/s]\n",
      "100%|##################################################################################| 78/78 [01:57<00:00,  1.49it/s]\n",
      "100%|####################################################################################| 2/2 [00:52<00:00, 36.87s/it]\n",
      "100%|##################################################################################| 98/98 [02:15<00:00,  1.56it/s]\n",
      "100%|##################################################################################| 78/78 [01:58<00:00,  1.49it/s]\n",
      "100%|####################################################################################| 2/2 [00:53<00:00, 37.12s/it]\n",
      "100%|##################################################################################| 98/98 [02:12<00:00,  1.54it/s]\n",
      "100%|##################################################################################| 78/78 [01:56<00:00,  1.51it/s]\n",
      "100%|####################################################################################| 2/2 [00:53<00:00, 37.15s/it]\n",
      "100%|##################################################################################| 98/98 [02:13<00:00,  1.57it/s]\n",
      "100%|##################################################################################| 78/78 [01:58<00:00,  1.52it/s]\n",
      "100%|####################################################################################| 2/2 [00:53<00:00, 37.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold  1\n",
      "train seresnext5032x4d\n",
      "train resnet110\n",
      "Single model pretrained respectively\n",
      "=> loading checkpoint './checkpoints/best_models//seresnext5032x4d-img224-FLlog-03washing-lr28-v0-final-batch32_fold_1_model_best_loss.pth.tar'\n",
      "Modifing model...\n",
      "Let's use 4 GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##################################################################################| 98/98 [02:11<00:00,  1.55it/s]\n",
      "100%|##################################################################################| 78/78 [02:01<00:00,  1.51it/s]\n",
      "100%|####################################################################################| 2/2 [00:52<00:00, 36.71s/it]\n",
      "100%|##################################################################################| 98/98 [02:13<00:00,  1.56it/s]\n",
      "100%|##################################################################################| 78/78 [01:57<00:00,  1.47it/s]\n",
      "100%|####################################################################################| 2/2 [00:53<00:00, 37.09s/it]\n",
      "100%|##################################################################################| 98/98 [02:14<00:00,  1.51it/s]\n",
      "100%|##################################################################################| 78/78 [01:56<00:00,  1.47it/s]\n",
      "100%|####################################################################################| 2/2 [00:52<00:00, 36.67s/it]\n",
      "100%|##################################################################################| 98/98 [02:13<00:00,  1.57it/s]\n",
      "100%|##################################################################################| 78/78 [01:59<00:00,  1.49it/s]\n",
      "100%|####################################################################################| 2/2 [00:53<00:00, 37.04s/it]\n",
      "100%|##################################################################################| 98/98 [02:14<00:00,  1.56it/s]\n",
      "100%|##################################################################################| 78/78 [01:56<00:00,  1.50it/s]\n",
      "100%|####################################################################################| 2/2 [00:52<00:00, 36.56s/it]\n",
      "100%|##################################################################################| 98/98 [02:14<00:00,  1.56it/s]\n",
      "100%|##################################################################################| 78/78 [01:56<00:00,  1.50it/s]\n",
      "100%|####################################################################################| 2/2 [00:53<00:00, 37.29s/it]\n",
      "100%|##################################################################################| 98/98 [02:13<00:00,  1.58it/s]\n",
      "100%|##################################################################################| 78/78 [01:57<00:00,  1.51it/s]\n",
      "100%|####################################################################################| 2/2 [00:53<00:00, 37.36s/it]\n",
      "100%|##################################################################################| 98/98 [02:15<00:00,  1.53it/s]\n",
      "100%|##################################################################################| 78/78 [01:58<00:00,  1.49it/s]\n",
      "100%|####################################################################################| 2/2 [00:53<00:00, 37.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold  2\n",
      "train seresnext5032x4d\n",
      "train resnet110\n",
      "Single model pretrained respectively\n",
      "=> loading checkpoint './checkpoints/best_models//seresnext5032x4d-img224-FLlog-03washing-lr28-v0-final-batch32_fold_2_model_best_loss.pth.tar'\n",
      "Modifing model...\n",
      "Let's use 4 GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##################################################################################| 98/98 [02:12<00:00,  1.56it/s]\n",
      "100%|##################################################################################| 78/78 [01:59<00:00,  1.48it/s]\n",
      "100%|####################################################################################| 2/2 [00:52<00:00, 36.72s/it]\n",
      "100%|##################################################################################| 98/98 [02:15<00:00,  1.56it/s]\n",
      "100%|##################################################################################| 78/78 [01:59<00:00,  1.51it/s]\n",
      "100%|####################################################################################| 2/2 [00:53<00:00, 37.04s/it]\n",
      "100%|##################################################################################| 98/98 [02:12<00:00,  1.56it/s]\n",
      "100%|##################################################################################| 78/78 [01:56<00:00,  1.51it/s]\n",
      "100%|####################################################################################| 2/2 [00:52<00:00, 36.88s/it]\n",
      "100%|##################################################################################| 98/98 [02:15<00:00,  1.53it/s]\n",
      "100%|##################################################################################| 78/78 [01:57<00:00,  1.49it/s]\n",
      "100%|####################################################################################| 2/2 [00:53<00:00, 37.08s/it]\n",
      "100%|##################################################################################| 98/98 [02:12<00:00,  1.52it/s]\n",
      "100%|##################################################################################| 78/78 [02:00<00:00,  1.48it/s]\n",
      "100%|####################################################################################| 2/2 [00:52<00:00, 36.68s/it]\n",
      "100%|##################################################################################| 98/98 [02:13<00:00,  1.56it/s]\n",
      "100%|##################################################################################| 78/78 [01:57<00:00,  1.45it/s]\n",
      "100%|####################################################################################| 2/2 [00:53<00:00, 37.18s/it]\n",
      "100%|##################################################################################| 98/98 [02:15<00:00,  1.58it/s]\n",
      "100%|##################################################################################| 78/78 [01:58<00:00,  1.48it/s]\n",
      "100%|####################################################################################| 2/2 [00:53<00:00, 37.06s/it]\n",
      "100%|##################################################################################| 98/98 [02:14<00:00,  1.58it/s]\n",
      "100%|##################################################################################| 78/78 [01:58<00:00,  1.45it/s]\n",
      "100%|####################################################################################| 2/2 [00:53<00:00, 37.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold  3\n",
      "train seresnext5032x4d\n",
      "train resnet110\n",
      "Single model pretrained respectively\n",
      "=> loading checkpoint './checkpoints/best_models//seresnext5032x4d-img224-FLlog-03washing-lr28-v0-final-batch32_fold_3_model_best_loss.pth.tar'\n",
      "Modifing model...\n",
      "Let's use 4 GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##################################################################################| 98/98 [02:12<00:00,  1.56it/s]\n",
      "100%|##################################################################################| 78/78 [01:56<00:00,  1.51it/s]\n",
      "100%|####################################################################################| 2/2 [00:52<00:00, 36.49s/it]\n",
      "100%|##################################################################################| 98/98 [02:13<00:00,  1.54it/s]\n",
      "100%|##################################################################################| 78/78 [02:00<00:00,  1.48it/s]\n",
      "100%|####################################################################################| 2/2 [00:53<00:00, 37.00s/it]\n",
      "100%|##################################################################################| 98/98 [02:13<00:00,  1.56it/s]\n",
      "100%|##################################################################################| 78/78 [01:58<00:00,  1.48it/s]\n",
      "100%|####################################################################################| 2/2 [00:53<00:00, 37.08s/it]\n",
      "100%|##################################################################################| 98/98 [02:16<00:00,  1.55it/s]\n",
      "100%|##################################################################################| 78/78 [01:58<00:00,  1.47it/s]\n",
      "100%|####################################################################################| 2/2 [00:52<00:00, 36.98s/it]\n",
      "100%|##################################################################################| 98/98 [02:14<00:00,  1.57it/s]\n",
      "100%|##################################################################################| 78/78 [01:58<00:00,  1.49it/s]\n",
      "100%|####################################################################################| 2/2 [00:52<00:00, 36.78s/it]\n",
      "100%|##################################################################################| 98/98 [02:13<00:00,  1.56it/s]\n",
      "100%|##################################################################################| 78/78 [01:57<00:00,  1.49it/s]\n",
      "100%|####################################################################################| 2/2 [00:53<00:00, 37.15s/it]\n",
      "100%|##################################################################################| 98/98 [02:15<00:00,  1.58it/s]\n",
      "100%|##################################################################################| 78/78 [01:59<00:00,  1.49it/s]\n",
      "100%|####################################################################################| 2/2 [00:53<00:00, 37.02s/it]\n",
      "100%|##################################################################################| 98/98 [02:14<00:00,  1.57it/s]\n",
      "100%|##################################################################################| 78/78 [01:59<00:00,  1.49it/s]\n",
      "100%|####################################################################################| 2/2 [00:53<00:00, 37.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold  4\n",
      "train seresnext5032x4d\n",
      "train resnet110\n",
      "Single model pretrained respectively\n",
      "=> loading checkpoint './checkpoints/best_models//seresnext5032x4d-img224-FLlog-03washing-lr28-v0-final-batch32_fold_4_model_best_loss.pth.tar'\n",
      "Modifing model...\n",
      "Let's use 4 GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##################################################################################| 98/98 [02:13<00:00,  1.57it/s]\n",
      "100%|##################################################################################| 78/78 [02:36<00:00, 12.00s/it]\n",
      "100%|####################################################################################| 2/2 [00:52<00:00, 36.64s/it]\n",
      "100%|##################################################################################| 98/98 [02:16<00:00,  1.58it/s]\n",
      "100%|##################################################################################| 78/78 [02:00<00:00,  1.49it/s]\n",
      "100%|####################################################################################| 2/2 [00:53<00:00, 37.21s/it]\n",
      "100%|##################################################################################| 98/98 [02:12<00:00,  1.57it/s]\n",
      "100%|##################################################################################| 78/78 [01:56<00:00,  1.50it/s]\n",
      "100%|####################################################################################| 2/2 [00:52<00:00, 36.96s/it]\n",
      "100%|##################################################################################| 98/98 [02:12<00:00,  1.51it/s]\n",
      "100%|##################################################################################| 78/78 [01:57<00:00,  1.48it/s]\n",
      "100%|####################################################################################| 2/2 [00:53<00:00, 37.17s/it]\n",
      "100%|##################################################################################| 98/98 [02:14<00:00,  1.55it/s]\n",
      "100%|##################################################################################| 78/78 [01:56<00:00,  1.51it/s]\n",
      "100%|####################################################################################| 2/2 [00:52<00:00, 36.72s/it]\n",
      "100%|##################################################################################| 98/98 [02:15<00:00,  1.52it/s]\n",
      "100%|##################################################################################| 78/78 [01:58<00:00,  1.51it/s]\n",
      "100%|####################################################################################| 2/2 [00:53<00:00, 37.23s/it]\n",
      "100%|##################################################################################| 98/98 [02:14<00:00,  1.53it/s]\n",
      "100%|##################################################################################| 78/78 [01:59<00:00,  1.50it/s]\n",
      "100%|####################################################################################| 2/2 [00:53<00:00, 37.27s/it]\n",
      "100%|##################################################################################| 98/98 [02:11<00:00,  1.50it/s]\n",
      "100%|##################################################################################| 78/78 [01:57<00:00,  1.51it/s]\n",
      "100%|####################################################################################| 2/2 [00:53<00:00, 37.21s/it]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    all_files = pd.read_csv(\"./dataset/final_train.csv\")\n",
    "#     all_files.Id_y = all_files.Id_y.apply(lambda x: x.replace(\"visit\", \"visit182\"))\n",
    "    all_files = all_files.loc[~(all_files.black_ratio<0.3)]#|(all_files.same_pixel>70)\n",
    "\t#print(all_files)\n",
    "    test_files = pd.read_csv(\"./dataset/final_test.csv\")\n",
    "    # test_files.Id_x = test_files.Id_x.apply(lambda x: \".\"+x)\n",
    "#     test_files.Id_y = test_files.Id_y.apply(lambda x: x.replace(\"visit\", \"visit182\"))\n",
    "\n",
    "#     config.model_name = \"seresnext5032x4d_resnet110-CE-03washing-v0-182v-imgpre-addchusai\"#\"seresnext5032x4d_resnet110-CE-03washing-v0-segpre\"\n",
    "#     config.model_name = \"seresnext5032x4d_resnet110-CE-03washing-v0-182v+log-segpre-addchusaino0-imgdehaze\"#去噪+dist+logv\n",
    "    all_pred = []\n",
    "    all_pred_tr = []\n",
    "    all_pred_val = []\n",
    "    labels_tr = []\n",
    "    labels_val = []\n",
    "    for fold in range(5):\n",
    "        print( \"\\nFold \", fold)\n",
    "        model = MultiModalNet(config, sep_pretrained=True, visit_channels=7, fold=fold)\n",
    "        model.modify_model()\n",
    "        val_files = pd.read_csv(\"./temp/final_X_val%s.csv\"%fold)\n",
    "        # MultiGpu\n",
    "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        if torch.cuda.device_count() >= 1:\n",
    "            print(\"Let's use\", torch.cuda.device_count(), \"GPUs\")\n",
    "            # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n",
    "            model = nn.DataParallel(model)#, device_ids=[0, 2]\n",
    "        model.to(device)\n",
    "\n",
    "        best_model = torch.load(\"%s/%s_fold_%s_model_best_loss.pth.tar\"%(config.best_models, config.model_name, str(fold)))\n",
    "        model.load_state_dict(best_model[\"state_dict\"])\n",
    "    \n",
    "        for i in range(8):\n",
    "            all_train_gen = PlanetDataset(val_files, augument=False, mode=\"test\", dtype=\"mixed\", config=config, transforms_id=i)\n",
    "            all_train_loader = DataLoader(all_train_gen, 256*4,shuffle=False,pin_memory=True,num_workers=16)\n",
    "            b_train_gen = PlanetDataset(all_files, augument=False, mode=\"test\", dtype=\"mixed\", config=config, transforms_id=i)\n",
    "            b_train_loader = DataLoader(b_train_gen, 256*4,shuffle=False,pin_memory=True,num_workers=16)\n",
    "            test_gen = PlanetDataset(test_files, augument=False, mode=\"test\", dtype=\"mixed\", config=config, transforms_id=i)\n",
    "            test_loader = DataLoader(test_gen, 256*4, shuffle=False, pin_memory=True, num_workers=16)\n",
    "\n",
    "            labels_fold, labels_tr_fold, labels_b_fold = test(test_loader, model, fold, all_train_loaders=[all_train_loader, b_train_loader])\n",
    "            all_pred.append(labels_fold)\n",
    "            all_pred_tr.append(labels_tr_fold)\n",
    "            all_pred_val.append(labels_b_fold)\n",
    "#             all_pred_tr.append(labels_tr_fold)\n",
    "#         np.save(\"./results/test182_addcs_bestloss.npy\", all_pred)\n",
    "#         np.save(\"./results/train182_addcs_bestloss.npy\", all_pred)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(398659, 10)\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for i in range(5):\n",
    "    results.append(np.mean(all_pred_tr[i*8: (i*8+8)], 0))\n",
    "results_tr = np.vstack(results)\n",
    "print(results_tr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results_tr[:, 9] = results_tr[:, 9].astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.30000e+01, 1.70000e+01, 2.10000e+01, ..., 3.99881e+05,\n",
       "       3.99896e+05, 3.99988e+05])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_tr[:, 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 9)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "for i in range(5):\n",
    "    results.append(np.mean(all_pred[i*8: (i*8+8)], 0))\n",
    "results_te = np.mean(results, 0)\n",
    "results_te.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1341, 10)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "for i in range(5):\n",
    "    results.append(np.mean(all_pred_val[i*8: (i*8+8)], 0))\n",
    "results_tr_b = np.mean(results, 0)\n",
    "results_tr_b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results_tr_b = np.hstack((results_tr_b, test_files.basename.values.reshape((-1, 1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400000, 10)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = np.vstack([results_tr, results_tr_b])\n",
    "results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save(\"./stacking/test7_oof_addcs_orig.npy\", results_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save(\"./stacking/test7_oof_visit_orig.npy\", np.mean(all_pred, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save(\"./stacking/test7_192img_oof_orig.npy\", results_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.save(\"./stacking/train7_oof_visit_orig.npy\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.save(\"./stacking/train7_192img_oof_orig.npy\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400000, 10)\n",
      "(100000, 9)\n"
     ]
    }
   ],
   "source": [
    "# visit\n",
    "results = np.vstack([np.vstack(all_pred_tr), np.mean(all_pred_val, 0)])\n",
    "print(results.shape)\n",
    "np.save(\"./stacking/train7_oof_visit_orig.npy\", results)\n",
    "print(np.mean(all_pred, 0).shape)\n",
    "np.save(\"./stacking/test7_oof_visit_orig.npy\", np.mean(all_pred, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# correct solution:\n",
    "def softmax(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum(axis=0) # only difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5264755 , 0.06973959, 0.0022421 , 0.00553492, 0.00002445,\n",
       "       0.02236212, 0.01376571, 0.02047716, 0.33937848], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax(results_tr_b.T).T[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.8940768 ,  0.8726406 , -2.5647166 , ..., -0.7499459 ,\n",
       "        -0.3528169 ,  2.454988  ],\n",
       "       [ 1.6143271 ,  0.1245259 ,  2.239495  , ...,  1.2305094 ,\n",
       "        -1.6487957 , -1.5342503 ],\n",
       "       [ 1.3956559 ,  0.92694914,  1.5661005 , ...,  1.0466396 ,\n",
       "        -2.3046355 , -2.0994678 ],\n",
       "       ...,\n",
       "       [ 4.5450287 ,  0.77550787, -0.41005713, ..., -1.9173464 ,\n",
       "        -0.7988874 , -0.8545507 ],\n",
       "       [ 4.1012583 ,  1.5728486 , -0.5812508 , ...,  0.04408486,\n",
       "        -0.93905944, -1.0305606 ],\n",
       "       [ 4.200846  ,  0.21507902, -1.9294401 , ...,  1.3776729 ,\n",
       "        -0.58340347, -0.29319698]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_tr_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.save(\"./stacking/test7_oof.npy\", results_tr_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fold5182 = np.squeeze(all_pred).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 100000, 9)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fold5 = np.squeeze(all_pred).copy()\n",
    "fold5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 9)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fold5 = np.mean(fold5, 0)\n",
    "fold5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = np.zeros((5, 100000, 9))\n",
    "\n",
    "for i in range(5):\n",
    "    data[i, :, :] = np.mean(fold5[i:(i*8+8)], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fold = np.load(\"./fusion/test7.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 9)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fold5 = np.mean(fold, 0)\n",
    "fold5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"./fusion/meow_test1.pkl\", 'rb') as f:\n",
    "    model1 = pickle.load(f)\n",
    "result = 0\n",
    "for key in [str(i) for i in range(5)]:\n",
    "    result += model1[key]\n",
    "result /= 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 9)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.7964071 , 0.04848755, 0.00019563, 0.00148878, 0.00000043,\n",
       "        0.03733421, 0.03366304, 0.01041587, 0.07200748],\n",
       "       [0.04991202, 0.02756109, 0.12903196, 0.69894725, 0.00000005,\n",
       "        0.01240712, 0.07457936, 0.00288484, 0.00467634],\n",
       "       [0.32507944, 0.04853205, 0.36576387, 0.00094881, 0.10286842,\n",
       "        0.08923764, 0.05260446, 0.00234388, 0.01262144],\n",
       "       [0.593215  , 0.0276758 , 0.00049242, 0.00007384, 0.00000003,\n",
       "        0.37284526, 0.00135877, 0.00196207, 0.00237675],\n",
       "       [0.63252026, 0.09085535, 0.03664375, 0.00011   , 0.00000002,\n",
       "        0.04316987, 0.05433962, 0.00964581, 0.13271542]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_files = pd.read_csv(\"./dataset/train.csv\")\n",
    "all_files.basename = all_files.basename.apply(lambda x: int(x[:6])+400000)\n",
    "all_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id_x</th>\n",
       "      <th>Target</th>\n",
       "      <th>black_ratio</th>\n",
       "      <th>basename</th>\n",
       "      <th>Id_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./dataset/final_train/001\\000003_001.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>./dataset/train_partarray/3\\000003_001.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./dataset/final_train/001\\000007_001.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>./dataset/train_partarray/7\\000007_001.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./dataset/final_train/001\\000008_001.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8</td>\n",
       "      <td>./dataset/train_partarray/8\\000008_001.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./dataset/final_train/001\\000009_001.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>./dataset/train_partarray/9\\000009_001.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./dataset/final_train/001\\000013_001.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13</td>\n",
       "      <td>./dataset/train_partarray/3\\000013_001.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>./dataset/final_train/001\\000015_001.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15</td>\n",
       "      <td>./dataset/train_partarray/5\\000015_001.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>./dataset/final_train/001\\000016_001.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16</td>\n",
       "      <td>./dataset/train_partarray/6\\000016_001.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>./dataset/final_train/001\\000017_001.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17</td>\n",
       "      <td>./dataset/train_partarray/7\\000017_001.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>./dataset/final_train/001\\000021_001.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21</td>\n",
       "      <td>./dataset/train_partarray/1\\000021_001.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>./dataset/final_train/001\\000024_001.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>./dataset/train_partarray/4\\000024_001.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>./dataset/final_train/001\\000025_001.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25</td>\n",
       "      <td>./dataset/train_partarray/5\\000025_001.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>./dataset/final_train/001\\000030_001.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30</td>\n",
       "      <td>./dataset/train_partarray/0\\000030_001.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>./dataset/final_train/001\\000031_001.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31</td>\n",
       "      <td>./dataset/train_partarray/1\\000031_001.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>./dataset/final_train/001\\000032_001.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32</td>\n",
       "      <td>./dataset/train_partarray/2\\000032_001.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>./dataset/final_train/001\\000039_001.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>39</td>\n",
       "      <td>./dataset/train_partarray/9\\000039_001.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>./dataset/final_train/001\\000041_001.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41</td>\n",
       "      <td>./dataset/train_partarray/1\\000041_001.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>./dataset/final_train/001\\000047_001.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>47</td>\n",
       "      <td>./dataset/train_partarray/7\\000047_001.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>./dataset/final_train/001\\000050_001.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50</td>\n",
       "      <td>./dataset/train_partarray/0\\000050_001.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>./dataset/final_train/001\\000051_001.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>51</td>\n",
       "      <td>./dataset/train_partarray/1\\000051_001.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>./dataset/final_train/001\\000053_001.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>53</td>\n",
       "      <td>./dataset/train_partarray/3\\000053_001.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>./dataset/final_train/001\\000057_001.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57</td>\n",
       "      <td>./dataset/train_partarray/7\\000057_001.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>./dataset/final_train/001\\000074_001.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>74</td>\n",
       "      <td>./dataset/train_partarray/4\\000074_001.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>./dataset/final_train/001\\000083_001.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>83</td>\n",
       "      <td>./dataset/train_partarray/3\\000083_001.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>./dataset/final_train/001\\000086_001.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>86</td>\n",
       "      <td>./dataset/train_partarray/6\\000086_001.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>./dataset/final_train/001\\000088_001.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>88</td>\n",
       "      <td>./dataset/train_partarray/8\\000088_001.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>./dataset/final_train/001\\000089_001.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>89</td>\n",
       "      <td>./dataset/train_partarray/9\\000089_001.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>./dataset/final_train/001\\000091_001.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>91</td>\n",
       "      <td>./dataset/train_partarray/1\\000091_001.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>./dataset/final_train/001\\000094_001.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>94</td>\n",
       "      <td>./dataset/train_partarray/4\\000094_001.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>./dataset/final_train/001\\000095_001.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>95</td>\n",
       "      <td>./dataset/train_partarray/5\\000095_001.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>./dataset/final_train/001\\000096_001.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>96</td>\n",
       "      <td>./dataset/train_partarray/6\\000096_001.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399970</th>\n",
       "      <td>./dataset/final_train/009\\399218_009.jpg</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>399218</td>\n",
       "      <td>./dataset/train_partarray/8\\399218_009.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399971</th>\n",
       "      <td>./dataset/final_train/009\\399231_009.jpg</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>399231</td>\n",
       "      <td>./dataset/train_partarray/1\\399231_009.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399972</th>\n",
       "      <td>./dataset/final_train/009\\399240_009.jpg</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>399240</td>\n",
       "      <td>./dataset/train_partarray/0\\399240_009.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399973</th>\n",
       "      <td>./dataset/final_train/009\\399279_009.jpg</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>399279</td>\n",
       "      <td>./dataset/train_partarray/9\\399279_009.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399974</th>\n",
       "      <td>./dataset/final_train/009\\399358_009.jpg</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>399358</td>\n",
       "      <td>./dataset/train_partarray/8\\399358_009.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399975</th>\n",
       "      <td>./dataset/final_train/009\\399365_009.jpg</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>399365</td>\n",
       "      <td>./dataset/train_partarray/5\\399365_009.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399976</th>\n",
       "      <td>./dataset/final_train/009\\399400_009.jpg</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>399400</td>\n",
       "      <td>./dataset/train_partarray/0\\399400_009.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399977</th>\n",
       "      <td>./dataset/final_train/009\\399419_009.jpg</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>399419</td>\n",
       "      <td>./dataset/train_partarray/9\\399419_009.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399978</th>\n",
       "      <td>./dataset/final_train/009\\399428_009.jpg</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>399428</td>\n",
       "      <td>./dataset/train_partarray/8\\399428_009.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399979</th>\n",
       "      <td>./dataset/final_train/009\\399445_009.jpg</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>399445</td>\n",
       "      <td>./dataset/train_partarray/5\\399445_009.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399980</th>\n",
       "      <td>./dataset/final_train/009\\399469_009.jpg</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>399469</td>\n",
       "      <td>./dataset/train_partarray/9\\399469_009.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399981</th>\n",
       "      <td>./dataset/final_train/009\\399481_009.jpg</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>399481</td>\n",
       "      <td>./dataset/train_partarray/1\\399481_009.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399982</th>\n",
       "      <td>./dataset/final_train/009\\399484_009.jpg</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>399484</td>\n",
       "      <td>./dataset/train_partarray/4\\399484_009.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399983</th>\n",
       "      <td>./dataset/final_train/009\\399542_009.jpg</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>399542</td>\n",
       "      <td>./dataset/train_partarray/2\\399542_009.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399984</th>\n",
       "      <td>./dataset/final_train/009\\399591_009.jpg</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>399591</td>\n",
       "      <td>./dataset/train_partarray/1\\399591_009.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399985</th>\n",
       "      <td>./dataset/final_train/009\\399640_009.jpg</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>399640</td>\n",
       "      <td>./dataset/train_partarray/0\\399640_009.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399986</th>\n",
       "      <td>./dataset/final_train/009\\399659_009.jpg</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>399659</td>\n",
       "      <td>./dataset/train_partarray/9\\399659_009.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399987</th>\n",
       "      <td>./dataset/final_train/009\\399667_009.jpg</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>399667</td>\n",
       "      <td>./dataset/train_partarray/7\\399667_009.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399988</th>\n",
       "      <td>./dataset/final_train/009\\399680_009.jpg</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>399680</td>\n",
       "      <td>./dataset/train_partarray/0\\399680_009.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399989</th>\n",
       "      <td>./dataset/final_train/009\\399687_009.jpg</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>399687</td>\n",
       "      <td>./dataset/train_partarray/7\\399687_009.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399990</th>\n",
       "      <td>./dataset/final_train/009\\399710_009.jpg</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>399710</td>\n",
       "      <td>./dataset/train_partarray/0\\399710_009.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399991</th>\n",
       "      <td>./dataset/final_train/009\\399713_009.jpg</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>399713</td>\n",
       "      <td>./dataset/train_partarray/3\\399713_009.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399992</th>\n",
       "      <td>./dataset/final_train/009\\399788_009.jpg</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>399788</td>\n",
       "      <td>./dataset/train_partarray/8\\399788_009.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399993</th>\n",
       "      <td>./dataset/final_train/009\\399875_009.jpg</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>399875</td>\n",
       "      <td>./dataset/train_partarray/5\\399875_009.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399994</th>\n",
       "      <td>./dataset/final_train/009\\399881_009.jpg</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>399881</td>\n",
       "      <td>./dataset/train_partarray/1\\399881_009.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399995</th>\n",
       "      <td>./dataset/final_train/009\\399896_009.jpg</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>399896</td>\n",
       "      <td>./dataset/train_partarray/6\\399896_009.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399996</th>\n",
       "      <td>./dataset/final_train/009\\399938_009.jpg</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>399938</td>\n",
       "      <td>./dataset/train_partarray/8\\399938_009.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399997</th>\n",
       "      <td>./dataset/final_train/009\\399988_009.jpg</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>399988</td>\n",
       "      <td>./dataset/train_partarray/8\\399988_009.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399998</th>\n",
       "      <td>./dataset/final_train/009\\399990_009.jpg</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>399990</td>\n",
       "      <td>./dataset/train_partarray/0\\399990_009.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399999</th>\n",
       "      <td>./dataset/final_train/009\\399993_009.jpg</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>399993</td>\n",
       "      <td>./dataset/train_partarray/3\\399993_009.npy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Id_x  Target  black_ratio  \\\n",
       "0       ./dataset/final_train/001\\000003_001.jpg       0     0.000000   \n",
       "1       ./dataset/final_train/001\\000007_001.jpg       0     0.000000   \n",
       "2       ./dataset/final_train/001\\000008_001.jpg       0     0.000000   \n",
       "3       ./dataset/final_train/001\\000009_001.jpg       0     0.000000   \n",
       "4       ./dataset/final_train/001\\000013_001.jpg       0     0.000000   \n",
       "5       ./dataset/final_train/001\\000015_001.jpg       0     0.000000   \n",
       "6       ./dataset/final_train/001\\000016_001.jpg       0     0.000000   \n",
       "7       ./dataset/final_train/001\\000017_001.jpg       0     0.000000   \n",
       "8       ./dataset/final_train/001\\000021_001.jpg       0     0.000000   \n",
       "9       ./dataset/final_train/001\\000024_001.jpg       0     0.000000   \n",
       "10      ./dataset/final_train/001\\000025_001.jpg       0     0.000000   \n",
       "11      ./dataset/final_train/001\\000030_001.jpg       0     0.000000   \n",
       "12      ./dataset/final_train/001\\000031_001.jpg       0     0.000000   \n",
       "13      ./dataset/final_train/001\\000032_001.jpg       0     0.000000   \n",
       "14      ./dataset/final_train/001\\000039_001.jpg       0     0.000000   \n",
       "15      ./dataset/final_train/001\\000041_001.jpg       0     0.000000   \n",
       "16      ./dataset/final_train/001\\000047_001.jpg       0     0.000000   \n",
       "17      ./dataset/final_train/001\\000050_001.jpg       0     0.000000   \n",
       "18      ./dataset/final_train/001\\000051_001.jpg       0     0.000000   \n",
       "19      ./dataset/final_train/001\\000053_001.jpg       0     0.000000   \n",
       "20      ./dataset/final_train/001\\000057_001.jpg       0     0.000000   \n",
       "21      ./dataset/final_train/001\\000074_001.jpg       0     0.000000   \n",
       "22      ./dataset/final_train/001\\000083_001.jpg       0     0.000000   \n",
       "23      ./dataset/final_train/001\\000086_001.jpg       0     0.000000   \n",
       "24      ./dataset/final_train/001\\000088_001.jpg       0     0.000000   \n",
       "25      ./dataset/final_train/001\\000089_001.jpg       0     0.000000   \n",
       "26      ./dataset/final_train/001\\000091_001.jpg       0     0.000000   \n",
       "27      ./dataset/final_train/001\\000094_001.jpg       0     0.000067   \n",
       "28      ./dataset/final_train/001\\000095_001.jpg       0     0.000000   \n",
       "29      ./dataset/final_train/001\\000096_001.jpg       0     0.000000   \n",
       "...                                          ...     ...          ...   \n",
       "399970  ./dataset/final_train/009\\399218_009.jpg       8     0.000033   \n",
       "399971  ./dataset/final_train/009\\399231_009.jpg       8     0.000000   \n",
       "399972  ./dataset/final_train/009\\399240_009.jpg       8     0.000000   \n",
       "399973  ./dataset/final_train/009\\399279_009.jpg       8     0.000000   \n",
       "399974  ./dataset/final_train/009\\399358_009.jpg       8     0.000000   \n",
       "399975  ./dataset/final_train/009\\399365_009.jpg       8     0.000000   \n",
       "399976  ./dataset/final_train/009\\399400_009.jpg       8     0.000000   \n",
       "399977  ./dataset/final_train/009\\399419_009.jpg       8     0.000000   \n",
       "399978  ./dataset/final_train/009\\399428_009.jpg       8     0.000000   \n",
       "399979  ./dataset/final_train/009\\399445_009.jpg       8     0.000067   \n",
       "399980  ./dataset/final_train/009\\399469_009.jpg       8     0.000000   \n",
       "399981  ./dataset/final_train/009\\399481_009.jpg       8     0.000000   \n",
       "399982  ./dataset/final_train/009\\399484_009.jpg       8     0.000033   \n",
       "399983  ./dataset/final_train/009\\399542_009.jpg       8     0.000000   \n",
       "399984  ./dataset/final_train/009\\399591_009.jpg       8     0.000000   \n",
       "399985  ./dataset/final_train/009\\399640_009.jpg       8     0.000000   \n",
       "399986  ./dataset/final_train/009\\399659_009.jpg       8     0.000000   \n",
       "399987  ./dataset/final_train/009\\399667_009.jpg       8     0.000000   \n",
       "399988  ./dataset/final_train/009\\399680_009.jpg       8     0.000000   \n",
       "399989  ./dataset/final_train/009\\399687_009.jpg       8     0.000033   \n",
       "399990  ./dataset/final_train/009\\399710_009.jpg       8     0.000000   \n",
       "399991  ./dataset/final_train/009\\399713_009.jpg       8     0.000000   \n",
       "399992  ./dataset/final_train/009\\399788_009.jpg       8     0.000000   \n",
       "399993  ./dataset/final_train/009\\399875_009.jpg       8     0.000000   \n",
       "399994  ./dataset/final_train/009\\399881_009.jpg       8     0.000000   \n",
       "399995  ./dataset/final_train/009\\399896_009.jpg       8     0.000000   \n",
       "399996  ./dataset/final_train/009\\399938_009.jpg       8     0.000000   \n",
       "399997  ./dataset/final_train/009\\399988_009.jpg       8     0.000000   \n",
       "399998  ./dataset/final_train/009\\399990_009.jpg       8     0.000000   \n",
       "399999  ./dataset/final_train/009\\399993_009.jpg       8     0.000000   \n",
       "\n",
       "        basename                                        Id_y  \n",
       "0              3  ./dataset/train_partarray/3\\000003_001.npy  \n",
       "1              7  ./dataset/train_partarray/7\\000007_001.npy  \n",
       "2              8  ./dataset/train_partarray/8\\000008_001.npy  \n",
       "3              9  ./dataset/train_partarray/9\\000009_001.npy  \n",
       "4             13  ./dataset/train_partarray/3\\000013_001.npy  \n",
       "5             15  ./dataset/train_partarray/5\\000015_001.npy  \n",
       "6             16  ./dataset/train_partarray/6\\000016_001.npy  \n",
       "7             17  ./dataset/train_partarray/7\\000017_001.npy  \n",
       "8             21  ./dataset/train_partarray/1\\000021_001.npy  \n",
       "9             24  ./dataset/train_partarray/4\\000024_001.npy  \n",
       "10            25  ./dataset/train_partarray/5\\000025_001.npy  \n",
       "11            30  ./dataset/train_partarray/0\\000030_001.npy  \n",
       "12            31  ./dataset/train_partarray/1\\000031_001.npy  \n",
       "13            32  ./dataset/train_partarray/2\\000032_001.npy  \n",
       "14            39  ./dataset/train_partarray/9\\000039_001.npy  \n",
       "15            41  ./dataset/train_partarray/1\\000041_001.npy  \n",
       "16            47  ./dataset/train_partarray/7\\000047_001.npy  \n",
       "17            50  ./dataset/train_partarray/0\\000050_001.npy  \n",
       "18            51  ./dataset/train_partarray/1\\000051_001.npy  \n",
       "19            53  ./dataset/train_partarray/3\\000053_001.npy  \n",
       "20            57  ./dataset/train_partarray/7\\000057_001.npy  \n",
       "21            74  ./dataset/train_partarray/4\\000074_001.npy  \n",
       "22            83  ./dataset/train_partarray/3\\000083_001.npy  \n",
       "23            86  ./dataset/train_partarray/6\\000086_001.npy  \n",
       "24            88  ./dataset/train_partarray/8\\000088_001.npy  \n",
       "25            89  ./dataset/train_partarray/9\\000089_001.npy  \n",
       "26            91  ./dataset/train_partarray/1\\000091_001.npy  \n",
       "27            94  ./dataset/train_partarray/4\\000094_001.npy  \n",
       "28            95  ./dataset/train_partarray/5\\000095_001.npy  \n",
       "29            96  ./dataset/train_partarray/6\\000096_001.npy  \n",
       "...          ...                                         ...  \n",
       "399970    399218  ./dataset/train_partarray/8\\399218_009.npy  \n",
       "399971    399231  ./dataset/train_partarray/1\\399231_009.npy  \n",
       "399972    399240  ./dataset/train_partarray/0\\399240_009.npy  \n",
       "399973    399279  ./dataset/train_partarray/9\\399279_009.npy  \n",
       "399974    399358  ./dataset/train_partarray/8\\399358_009.npy  \n",
       "399975    399365  ./dataset/train_partarray/5\\399365_009.npy  \n",
       "399976    399400  ./dataset/train_partarray/0\\399400_009.npy  \n",
       "399977    399419  ./dataset/train_partarray/9\\399419_009.npy  \n",
       "399978    399428  ./dataset/train_partarray/8\\399428_009.npy  \n",
       "399979    399445  ./dataset/train_partarray/5\\399445_009.npy  \n",
       "399980    399469  ./dataset/train_partarray/9\\399469_009.npy  \n",
       "399981    399481  ./dataset/train_partarray/1\\399481_009.npy  \n",
       "399982    399484  ./dataset/train_partarray/4\\399484_009.npy  \n",
       "399983    399542  ./dataset/train_partarray/2\\399542_009.npy  \n",
       "399984    399591  ./dataset/train_partarray/1\\399591_009.npy  \n",
       "399985    399640  ./dataset/train_partarray/0\\399640_009.npy  \n",
       "399986    399659  ./dataset/train_partarray/9\\399659_009.npy  \n",
       "399987    399667  ./dataset/train_partarray/7\\399667_009.npy  \n",
       "399988    399680  ./dataset/train_partarray/0\\399680_009.npy  \n",
       "399989    399687  ./dataset/train_partarray/7\\399687_009.npy  \n",
       "399990    399710  ./dataset/train_partarray/0\\399710_009.npy  \n",
       "399991    399713  ./dataset/train_partarray/3\\399713_009.npy  \n",
       "399992    399788  ./dataset/train_partarray/8\\399788_009.npy  \n",
       "399993    399875  ./dataset/train_partarray/5\\399875_009.npy  \n",
       "399994    399881  ./dataset/train_partarray/1\\399881_009.npy  \n",
       "399995    399896  ./dataset/train_partarray/6\\399896_009.npy  \n",
       "399996    399938  ./dataset/train_partarray/8\\399938_009.npy  \n",
       "399997    399988  ./dataset/train_partarray/8\\399988_009.npy  \n",
       "399998    399990  ./dataset/train_partarray/0\\399990_009.npy  \n",
       "399999    399993  ./dataset/train_partarray/3\\399993_009.npy  \n",
       "\n",
       "[400000 rows x 5 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"./dataset/final_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id_x</th>\n",
       "      <th>Target</th>\n",
       "      <th>black_ratio</th>\n",
       "      <th>basename</th>\n",
       "      <th>Id_y</th>\n",
       "      <th>max_min_pixel</th>\n",
       "      <th>same_pixel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./dataset/train\\001\\000009_001.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>000009_001</td>\n",
       "      <td>./dataset/train_visitarray/000009_001.npy</td>\n",
       "      <td>[765, 120]</td>\n",
       "      <td>645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./dataset/train\\001\\000018_001.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>000018_001</td>\n",
       "      <td>./dataset/train_visitarray/000018_001.npy</td>\n",
       "      <td>[760, 162]</td>\n",
       "      <td>598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./dataset/train\\001\\000020_001.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>000020_001</td>\n",
       "      <td>./dataset/train_visitarray/000020_001.npy</td>\n",
       "      <td>[763, 202]</td>\n",
       "      <td>561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./dataset/train\\001\\000024_001.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>000024_001</td>\n",
       "      <td>./dataset/train_visitarray/000024_001.npy</td>\n",
       "      <td>[763, 386]</td>\n",
       "      <td>377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./dataset/train\\001\\000026_001.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>000026_001</td>\n",
       "      <td>./dataset/train_visitarray/000026_001.npy</td>\n",
       "      <td>[763, 326]</td>\n",
       "      <td>437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>./dataset/train\\001\\000029_001.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>000029_001</td>\n",
       "      <td>./dataset/train_visitarray/000029_001.npy</td>\n",
       "      <td>[764, 295]</td>\n",
       "      <td>469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>./dataset/train\\001\\000031_001.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>000031_001</td>\n",
       "      <td>./dataset/train_visitarray/000031_001.npy</td>\n",
       "      <td>[755, 373]</td>\n",
       "      <td>382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>./dataset/train\\001\\000037_001.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>000037_001</td>\n",
       "      <td>./dataset/train_visitarray/000037_001.npy</td>\n",
       "      <td>[757, 196]</td>\n",
       "      <td>561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>./dataset/train\\001\\000062_001.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>000062_001</td>\n",
       "      <td>./dataset/train_visitarray/000062_001.npy</td>\n",
       "      <td>[643, 219]</td>\n",
       "      <td>424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>./dataset/train\\001\\000063_001.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>000063_001</td>\n",
       "      <td>./dataset/train_visitarray/000063_001.npy</td>\n",
       "      <td>[752, 215]</td>\n",
       "      <td>537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>./dataset/train\\001\\000064_001.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>000064_001</td>\n",
       "      <td>./dataset/train_visitarray/000064_001.npy</td>\n",
       "      <td>[409, 269]</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>./dataset/train\\001\\000068_001.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>000068_001</td>\n",
       "      <td>./dataset/train_visitarray/000068_001.npy</td>\n",
       "      <td>[765, 223]</td>\n",
       "      <td>542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>./dataset/train\\001\\000071_001.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>000071_001</td>\n",
       "      <td>./dataset/train_visitarray/000071_001.npy</td>\n",
       "      <td>[758, 117]</td>\n",
       "      <td>641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>./dataset/train\\001\\000086_001.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>000086_001</td>\n",
       "      <td>./dataset/train_visitarray/000086_001.npy</td>\n",
       "      <td>[754, 108]</td>\n",
       "      <td>646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>./dataset/train\\001\\000087_001.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>000087_001</td>\n",
       "      <td>./dataset/train_visitarray/000087_001.npy</td>\n",
       "      <td>[517, 302]</td>\n",
       "      <td>215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>./dataset/train\\001\\000088_001.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>000088_001</td>\n",
       "      <td>./dataset/train_visitarray/000088_001.npy</td>\n",
       "      <td>[763, 264]</td>\n",
       "      <td>499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>./dataset/train\\001\\000091_001.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>000091_001</td>\n",
       "      <td>./dataset/train_visitarray/000091_001.npy</td>\n",
       "      <td>[759, 258]</td>\n",
       "      <td>501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>./dataset/train\\001\\000098_001.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>000098_001</td>\n",
       "      <td>./dataset/train_visitarray/000098_001.npy</td>\n",
       "      <td>[752, 429]</td>\n",
       "      <td>323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>./dataset/train\\001\\000099_001.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>000099_001</td>\n",
       "      <td>./dataset/train_visitarray/000099_001.npy</td>\n",
       "      <td>[761, 94]</td>\n",
       "      <td>667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>./dataset/train\\001\\000101_001.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>000101_001</td>\n",
       "      <td>./dataset/train_visitarray/000101_001.npy</td>\n",
       "      <td>[695, 240]</td>\n",
       "      <td>455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>./dataset/train\\001\\000110_001.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>000110_001</td>\n",
       "      <td>./dataset/train_visitarray/000110_001.npy</td>\n",
       "      <td>[764, 57]</td>\n",
       "      <td>707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>./dataset/train\\001\\000115_001.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>000115_001</td>\n",
       "      <td>./dataset/train_visitarray/000115_001.npy</td>\n",
       "      <td>[763, 24]</td>\n",
       "      <td>739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>./dataset/train\\001\\000116_001.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>000116_001</td>\n",
       "      <td>./dataset/train_visitarray/000116_001.npy</td>\n",
       "      <td>[756, 263]</td>\n",
       "      <td>493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>./dataset/train\\001\\000117_001.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>000117_001</td>\n",
       "      <td>./dataset/train_visitarray/000117_001.npy</td>\n",
       "      <td>[764, 320]</td>\n",
       "      <td>444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>./dataset/train\\001\\000125_001.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>000125_001</td>\n",
       "      <td>./dataset/train_visitarray/000125_001.npy</td>\n",
       "      <td>[756, 449]</td>\n",
       "      <td>307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>./dataset/train\\001\\000129_001.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>000129_001</td>\n",
       "      <td>./dataset/train_visitarray/000129_001.npy</td>\n",
       "      <td>[562, 221]</td>\n",
       "      <td>341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>./dataset/train\\001\\000132_001.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>000132_001</td>\n",
       "      <td>./dataset/train_visitarray/000132_001.npy</td>\n",
       "      <td>[765, 256]</td>\n",
       "      <td>509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>./dataset/train\\001\\000138_001.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>000138_001</td>\n",
       "      <td>./dataset/train_visitarray/000138_001.npy</td>\n",
       "      <td>[765, 161]</td>\n",
       "      <td>604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>./dataset/train\\001\\000139_001.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>000139_001</td>\n",
       "      <td>./dataset/train_visitarray/000139_001.npy</td>\n",
       "      <td>[743, 396]</td>\n",
       "      <td>347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>./dataset/train\\001\\000157_001.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>000157_001</td>\n",
       "      <td>./dataset/train_visitarray/000157_001.npy</td>\n",
       "      <td>[410, 213]</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39970</th>\n",
       "      <td>./dataset/train\\009\\039474_009.jpg</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>039474_009</td>\n",
       "      <td>./dataset/train_visitarray/039474_009.npy</td>\n",
       "      <td>[765, 379]</td>\n",
       "      <td>386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39971</th>\n",
       "      <td>./dataset/train\\009\\039480_009.jpg</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>039480_009</td>\n",
       "      <td>./dataset/train_visitarray/039480_009.npy</td>\n",
       "      <td>[461, 236]</td>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39972</th>\n",
       "      <td>./dataset/train\\009\\039489_009.jpg</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>039489_009</td>\n",
       "      <td>./dataset/train_visitarray/039489_009.npy</td>\n",
       "      <td>[759, 378]</td>\n",
       "      <td>381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39973</th>\n",
       "      <td>./dataset/train\\009\\039499_009.jpg</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>039499_009</td>\n",
       "      <td>./dataset/train_visitarray/039499_009.npy</td>\n",
       "      <td>[758, 81]</td>\n",
       "      <td>677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39974</th>\n",
       "      <td>./dataset/train\\009\\039501_009.jpg</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>039501_009</td>\n",
       "      <td>./dataset/train_visitarray/039501_009.npy</td>\n",
       "      <td>[747, 200]</td>\n",
       "      <td>547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39975</th>\n",
       "      <td>./dataset/train\\009\\039509_009.jpg</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>039509_009</td>\n",
       "      <td>./dataset/train_visitarray/039509_009.npy</td>\n",
       "      <td>[737, 240]</td>\n",
       "      <td>497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39976</th>\n",
       "      <td>./dataset/train\\009\\039525_009.jpg</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>039525_009</td>\n",
       "      <td>./dataset/train_visitarray/039525_009.npy</td>\n",
       "      <td>[762, 321]</td>\n",
       "      <td>441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39977</th>\n",
       "      <td>./dataset/train\\009\\039568_009.jpg</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>039568_009</td>\n",
       "      <td>./dataset/train_visitarray/039568_009.npy</td>\n",
       "      <td>[764, 294]</td>\n",
       "      <td>470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39978</th>\n",
       "      <td>./dataset/train\\009\\039596_009.jpg</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>039596_009</td>\n",
       "      <td>./dataset/train_visitarray/039596_009.npy</td>\n",
       "      <td>[703, 155]</td>\n",
       "      <td>548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39979</th>\n",
       "      <td>./dataset/train\\009\\039598_009.jpg</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>039598_009</td>\n",
       "      <td>./dataset/train_visitarray/039598_009.npy</td>\n",
       "      <td>[634, 310]</td>\n",
       "      <td>324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39980</th>\n",
       "      <td>./dataset/train\\009\\039603_009.jpg</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>039603_009</td>\n",
       "      <td>./dataset/train_visitarray/039603_009.npy</td>\n",
       "      <td>[623, 75]</td>\n",
       "      <td>548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39981</th>\n",
       "      <td>./dataset/train\\009\\039614_009.jpg</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>039614_009</td>\n",
       "      <td>./dataset/train_visitarray/039614_009.npy</td>\n",
       "      <td>[765, 262]</td>\n",
       "      <td>503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39982</th>\n",
       "      <td>./dataset/train\\009\\039624_009.jpg</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>039624_009</td>\n",
       "      <td>./dataset/train_visitarray/039624_009.npy</td>\n",
       "      <td>[765, 265]</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39983</th>\n",
       "      <td>./dataset/train\\009\\039636_009.jpg</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>039636_009</td>\n",
       "      <td>./dataset/train_visitarray/039636_009.npy</td>\n",
       "      <td>[543, 274]</td>\n",
       "      <td>269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39984</th>\n",
       "      <td>./dataset/train\\009\\039640_009.jpg</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>039640_009</td>\n",
       "      <td>./dataset/train_visitarray/039640_009.npy</td>\n",
       "      <td>[461, 217]</td>\n",
       "      <td>244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39985</th>\n",
       "      <td>./dataset/train\\009\\039698_009.jpg</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>039698_009</td>\n",
       "      <td>./dataset/train_visitarray/039698_009.npy</td>\n",
       "      <td>[765, 221]</td>\n",
       "      <td>544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39986</th>\n",
       "      <td>./dataset/train\\009\\039703_009.jpg</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>039703_009</td>\n",
       "      <td>./dataset/train_visitarray/039703_009.npy</td>\n",
       "      <td>[752, 276]</td>\n",
       "      <td>476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39987</th>\n",
       "      <td>./dataset/train\\009\\039707_009.jpg</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>039707_009</td>\n",
       "      <td>./dataset/train_visitarray/039707_009.npy</td>\n",
       "      <td>[764, 300]</td>\n",
       "      <td>464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39988</th>\n",
       "      <td>./dataset/train\\009\\039743_009.jpg</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>039743_009</td>\n",
       "      <td>./dataset/train_visitarray/039743_009.npy</td>\n",
       "      <td>[746, 176]</td>\n",
       "      <td>570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39989</th>\n",
       "      <td>./dataset/train\\009\\039757_009.jpg</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>039757_009</td>\n",
       "      <td>./dataset/train_visitarray/039757_009.npy</td>\n",
       "      <td>[750, 164]</td>\n",
       "      <td>586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39990</th>\n",
       "      <td>./dataset/train\\009\\039759_009.jpg</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>039759_009</td>\n",
       "      <td>./dataset/train_visitarray/039759_009.npy</td>\n",
       "      <td>[765, 274]</td>\n",
       "      <td>491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39991</th>\n",
       "      <td>./dataset/train\\009\\039835_009.jpg</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>039835_009</td>\n",
       "      <td>./dataset/train_visitarray/039835_009.npy</td>\n",
       "      <td>[764, 116]</td>\n",
       "      <td>648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39992</th>\n",
       "      <td>./dataset/train\\009\\039856_009.jpg</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>039856_009</td>\n",
       "      <td>./dataset/train_visitarray/039856_009.npy</td>\n",
       "      <td>[754, 101]</td>\n",
       "      <td>653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39993</th>\n",
       "      <td>./dataset/train\\009\\039866_009.jpg</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>039866_009</td>\n",
       "      <td>./dataset/train_visitarray/039866_009.npy</td>\n",
       "      <td>[754, 294]</td>\n",
       "      <td>460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39994</th>\n",
       "      <td>./dataset/train\\009\\039872_009.jpg</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>039872_009</td>\n",
       "      <td>./dataset/train_visitarray/039872_009.npy</td>\n",
       "      <td>[765, 166]</td>\n",
       "      <td>599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39995</th>\n",
       "      <td>./dataset/train\\009\\039898_009.jpg</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>039898_009</td>\n",
       "      <td>./dataset/train_visitarray/039898_009.npy</td>\n",
       "      <td>[764, 240]</td>\n",
       "      <td>524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39996</th>\n",
       "      <td>./dataset/train\\009\\039918_009.jpg</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>039918_009</td>\n",
       "      <td>./dataset/train_visitarray/039918_009.npy</td>\n",
       "      <td>[762, 34]</td>\n",
       "      <td>728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39997</th>\n",
       "      <td>./dataset/train\\009\\039951_009.jpg</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>039951_009</td>\n",
       "      <td>./dataset/train_visitarray/039951_009.npy</td>\n",
       "      <td>[754, 82]</td>\n",
       "      <td>672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39998</th>\n",
       "      <td>./dataset/train\\009\\039960_009.jpg</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>039960_009</td>\n",
       "      <td>./dataset/train_visitarray/039960_009.npy</td>\n",
       "      <td>[764, 86]</td>\n",
       "      <td>678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39999</th>\n",
       "      <td>./dataset/train\\009\\039973_009.jpg</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>039973_009</td>\n",
       "      <td>./dataset/train_visitarray/039973_009.npy</td>\n",
       "      <td>[765, 297]</td>\n",
       "      <td>468</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Id_x  Target  black_ratio    basename  \\\n",
       "0      ./dataset/train\\001\\000009_001.jpg       0     0.000000  000009_001   \n",
       "1      ./dataset/train\\001\\000018_001.jpg       0     0.000000  000018_001   \n",
       "2      ./dataset/train\\001\\000020_001.jpg       0     0.000000  000020_001   \n",
       "3      ./dataset/train\\001\\000024_001.jpg       0     0.000000  000024_001   \n",
       "4      ./dataset/train\\001\\000026_001.jpg       0     0.000000  000026_001   \n",
       "5      ./dataset/train\\001\\000029_001.jpg       0     0.000000  000029_001   \n",
       "6      ./dataset/train\\001\\000031_001.jpg       0     0.000000  000031_001   \n",
       "7      ./dataset/train\\001\\000037_001.jpg       0     0.000000  000037_001   \n",
       "8      ./dataset/train\\001\\000062_001.jpg       0     0.000000  000062_001   \n",
       "9      ./dataset/train\\001\\000063_001.jpg       0     0.000000  000063_001   \n",
       "10     ./dataset/train\\001\\000064_001.jpg       0     0.000000  000064_001   \n",
       "11     ./dataset/train\\001\\000068_001.jpg       0     0.000000  000068_001   \n",
       "12     ./dataset/train\\001\\000071_001.jpg       0     0.000000  000071_001   \n",
       "13     ./dataset/train\\001\\000086_001.jpg       0     0.000000  000086_001   \n",
       "14     ./dataset/train\\001\\000087_001.jpg       0     0.000000  000087_001   \n",
       "15     ./dataset/train\\001\\000088_001.jpg       0     0.000000  000088_001   \n",
       "16     ./dataset/train\\001\\000091_001.jpg       0     0.000000  000091_001   \n",
       "17     ./dataset/train\\001\\000098_001.jpg       0     0.000000  000098_001   \n",
       "18     ./dataset/train\\001\\000099_001.jpg       0     0.000000  000099_001   \n",
       "19     ./dataset/train\\001\\000101_001.jpg       0     0.000000  000101_001   \n",
       "20     ./dataset/train\\001\\000110_001.jpg       0     0.000033  000110_001   \n",
       "21     ./dataset/train\\001\\000115_001.jpg       0     0.000100  000115_001   \n",
       "22     ./dataset/train\\001\\000116_001.jpg       0     0.000000  000116_001   \n",
       "23     ./dataset/train\\001\\000117_001.jpg       0     0.000000  000117_001   \n",
       "24     ./dataset/train\\001\\000125_001.jpg       0     0.000000  000125_001   \n",
       "25     ./dataset/train\\001\\000129_001.jpg       0     0.000000  000129_001   \n",
       "26     ./dataset/train\\001\\000132_001.jpg       0     0.000000  000132_001   \n",
       "27     ./dataset/train\\001\\000138_001.jpg       0     0.000000  000138_001   \n",
       "28     ./dataset/train\\001\\000139_001.jpg       0     0.000000  000139_001   \n",
       "29     ./dataset/train\\001\\000157_001.jpg       0     0.000000  000157_001   \n",
       "...                                   ...     ...          ...         ...   \n",
       "39970  ./dataset/train\\009\\039474_009.jpg       8     0.000000  039474_009   \n",
       "39971  ./dataset/train\\009\\039480_009.jpg       8     0.000000  039480_009   \n",
       "39972  ./dataset/train\\009\\039489_009.jpg       8     0.000000  039489_009   \n",
       "39973  ./dataset/train\\009\\039499_009.jpg       8     0.000000  039499_009   \n",
       "39974  ./dataset/train\\009\\039501_009.jpg       8     0.000000  039501_009   \n",
       "39975  ./dataset/train\\009\\039509_009.jpg       8     0.000000  039509_009   \n",
       "39976  ./dataset/train\\009\\039525_009.jpg       8     0.000000  039525_009   \n",
       "39977  ./dataset/train\\009\\039568_009.jpg       8     0.000000  039568_009   \n",
       "39978  ./dataset/train\\009\\039596_009.jpg       8     0.000000  039596_009   \n",
       "39979  ./dataset/train\\009\\039598_009.jpg       8     0.000000  039598_009   \n",
       "39980  ./dataset/train\\009\\039603_009.jpg       8     0.000000  039603_009   \n",
       "39981  ./dataset/train\\009\\039614_009.jpg       8     0.000000  039614_009   \n",
       "39982  ./dataset/train\\009\\039624_009.jpg       8     0.000000  039624_009   \n",
       "39983  ./dataset/train\\009\\039636_009.jpg       8     0.000000  039636_009   \n",
       "39984  ./dataset/train\\009\\039640_009.jpg       8     0.000000  039640_009   \n",
       "39985  ./dataset/train\\009\\039698_009.jpg       8     0.000000  039698_009   \n",
       "39986  ./dataset/train\\009\\039703_009.jpg       8     0.000000  039703_009   \n",
       "39987  ./dataset/train\\009\\039707_009.jpg       8     0.000000  039707_009   \n",
       "39988  ./dataset/train\\009\\039743_009.jpg       8     0.000000  039743_009   \n",
       "39989  ./dataset/train\\009\\039757_009.jpg       8     0.000000  039757_009   \n",
       "39990  ./dataset/train\\009\\039759_009.jpg       8     0.000000  039759_009   \n",
       "39991  ./dataset/train\\009\\039835_009.jpg       8     0.000000  039835_009   \n",
       "39992  ./dataset/train\\009\\039856_009.jpg       8     0.000000  039856_009   \n",
       "39993  ./dataset/train\\009\\039866_009.jpg       8     0.000000  039866_009   \n",
       "39994  ./dataset/train\\009\\039872_009.jpg       8     0.000000  039872_009   \n",
       "39995  ./dataset/train\\009\\039898_009.jpg       8     0.000000  039898_009   \n",
       "39996  ./dataset/train\\009\\039918_009.jpg       8     0.000033  039918_009   \n",
       "39997  ./dataset/train\\009\\039951_009.jpg       8     0.000000  039951_009   \n",
       "39998  ./dataset/train\\009\\039960_009.jpg       8     0.000033  039960_009   \n",
       "39999  ./dataset/train\\009\\039973_009.jpg       8     0.000000  039973_009   \n",
       "\n",
       "                                            Id_y max_min_pixel  same_pixel  \n",
       "0      ./dataset/train_visitarray/000009_001.npy    [765, 120]         645  \n",
       "1      ./dataset/train_visitarray/000018_001.npy    [760, 162]         598  \n",
       "2      ./dataset/train_visitarray/000020_001.npy    [763, 202]         561  \n",
       "3      ./dataset/train_visitarray/000024_001.npy    [763, 386]         377  \n",
       "4      ./dataset/train_visitarray/000026_001.npy    [763, 326]         437  \n",
       "5      ./dataset/train_visitarray/000029_001.npy    [764, 295]         469  \n",
       "6      ./dataset/train_visitarray/000031_001.npy    [755, 373]         382  \n",
       "7      ./dataset/train_visitarray/000037_001.npy    [757, 196]         561  \n",
       "8      ./dataset/train_visitarray/000062_001.npy    [643, 219]         424  \n",
       "9      ./dataset/train_visitarray/000063_001.npy    [752, 215]         537  \n",
       "10     ./dataset/train_visitarray/000064_001.npy    [409, 269]         140  \n",
       "11     ./dataset/train_visitarray/000068_001.npy    [765, 223]         542  \n",
       "12     ./dataset/train_visitarray/000071_001.npy    [758, 117]         641  \n",
       "13     ./dataset/train_visitarray/000086_001.npy    [754, 108]         646  \n",
       "14     ./dataset/train_visitarray/000087_001.npy    [517, 302]         215  \n",
       "15     ./dataset/train_visitarray/000088_001.npy    [763, 264]         499  \n",
       "16     ./dataset/train_visitarray/000091_001.npy    [759, 258]         501  \n",
       "17     ./dataset/train_visitarray/000098_001.npy    [752, 429]         323  \n",
       "18     ./dataset/train_visitarray/000099_001.npy     [761, 94]         667  \n",
       "19     ./dataset/train_visitarray/000101_001.npy    [695, 240]         455  \n",
       "20     ./dataset/train_visitarray/000110_001.npy     [764, 57]         707  \n",
       "21     ./dataset/train_visitarray/000115_001.npy     [763, 24]         739  \n",
       "22     ./dataset/train_visitarray/000116_001.npy    [756, 263]         493  \n",
       "23     ./dataset/train_visitarray/000117_001.npy    [764, 320]         444  \n",
       "24     ./dataset/train_visitarray/000125_001.npy    [756, 449]         307  \n",
       "25     ./dataset/train_visitarray/000129_001.npy    [562, 221]         341  \n",
       "26     ./dataset/train_visitarray/000132_001.npy    [765, 256]         509  \n",
       "27     ./dataset/train_visitarray/000138_001.npy    [765, 161]         604  \n",
       "28     ./dataset/train_visitarray/000139_001.npy    [743, 396]         347  \n",
       "29     ./dataset/train_visitarray/000157_001.npy    [410, 213]         197  \n",
       "...                                          ...           ...         ...  \n",
       "39970  ./dataset/train_visitarray/039474_009.npy    [765, 379]         386  \n",
       "39971  ./dataset/train_visitarray/039480_009.npy    [461, 236]         225  \n",
       "39972  ./dataset/train_visitarray/039489_009.npy    [759, 378]         381  \n",
       "39973  ./dataset/train_visitarray/039499_009.npy     [758, 81]         677  \n",
       "39974  ./dataset/train_visitarray/039501_009.npy    [747, 200]         547  \n",
       "39975  ./dataset/train_visitarray/039509_009.npy    [737, 240]         497  \n",
       "39976  ./dataset/train_visitarray/039525_009.npy    [762, 321]         441  \n",
       "39977  ./dataset/train_visitarray/039568_009.npy    [764, 294]         470  \n",
       "39978  ./dataset/train_visitarray/039596_009.npy    [703, 155]         548  \n",
       "39979  ./dataset/train_visitarray/039598_009.npy    [634, 310]         324  \n",
       "39980  ./dataset/train_visitarray/039603_009.npy     [623, 75]         548  \n",
       "39981  ./dataset/train_visitarray/039614_009.npy    [765, 262]         503  \n",
       "39982  ./dataset/train_visitarray/039624_009.npy    [765, 265]         500  \n",
       "39983  ./dataset/train_visitarray/039636_009.npy    [543, 274]         269  \n",
       "39984  ./dataset/train_visitarray/039640_009.npy    [461, 217]         244  \n",
       "39985  ./dataset/train_visitarray/039698_009.npy    [765, 221]         544  \n",
       "39986  ./dataset/train_visitarray/039703_009.npy    [752, 276]         476  \n",
       "39987  ./dataset/train_visitarray/039707_009.npy    [764, 300]         464  \n",
       "39988  ./dataset/train_visitarray/039743_009.npy    [746, 176]         570  \n",
       "39989  ./dataset/train_visitarray/039757_009.npy    [750, 164]         586  \n",
       "39990  ./dataset/train_visitarray/039759_009.npy    [765, 274]         491  \n",
       "39991  ./dataset/train_visitarray/039835_009.npy    [764, 116]         648  \n",
       "39992  ./dataset/train_visitarray/039856_009.npy    [754, 101]         653  \n",
       "39993  ./dataset/train_visitarray/039866_009.npy    [754, 294]         460  \n",
       "39994  ./dataset/train_visitarray/039872_009.npy    [765, 166]         599  \n",
       "39995  ./dataset/train_visitarray/039898_009.npy    [764, 240]         524  \n",
       "39996  ./dataset/train_visitarray/039918_009.npy     [762, 34]         728  \n",
       "39997  ./dataset/train_visitarray/039951_009.npy     [754, 82]         672  \n",
       "39998  ./dataset/train_visitarray/039960_009.npy     [764, 86]         678  \n",
       "39999  ./dataset/train_visitarray/039973_009.npy    [765, 297]         468  \n",
       "\n",
       "[40000 rows x 7 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"./dataset/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## data_old---->train\n",
    "all_files_pre = pd.read_csv(\"./dataset/train.csv\")\n",
    "all_files.basename = all_files.basename.apply(lambda x: int(x[:6])+400000)\n",
    "all_files_pre = all_files_pre.loc[(all_files_pre.black_ratio<0.3)]\n",
    "\n",
    "k = 5\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=2050)\n",
    "\n",
    "train_index_pre, test_index_pre = [], []\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(all_files_pre)):\n",
    "    train_index_pre.append(train_index)\n",
    "    test_index_pre.append(test_index)\n",
    "\n",
    "#print(parameters)\n",
    "all_pred = []\n",
    "all_pred_tr = []\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(all_files, all_files.Target)):\n",
    "    X_tr, X_val= all_files.iloc[train_index,:].copy(), all_files.iloc[test_index,:].copy()\n",
    "    X_tr.to_csv(\"./temp/final_X_tr%s.csv\"%fold, index=False)\n",
    "    X_val.to_csv(\"./temp/final_X_val%s.csv\"%fold, index=False)\n",
    "    X_tr_pre, X_val_pre= all_files_pre.iloc[train_index_pre[fold],:].copy(), all_files_pre.iloc[test_index_pre[fold],:].copy()\n",
    "    X_tr = pd.concat([X_tr, X_tr_pre])\n",
    "    print( \"\\nFold \", fold)\n",
    "    print( \"X_tr's size \", X_tr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 9)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fold5182 = np.load(\"./fusion/test182.npy\")\n",
    "fold5182.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fold5 = np.squeeze(all_pred).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_files = pd.read_csv(\"./dataset/final_test.csv\")\n",
    "ID_values = test_files.loc[:, [\"Id_x\", \"Target\"]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AxisError",
     "evalue": "axis 1 is out of bounds for array of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-bcfa4195bfab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mID_values\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfold5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Softwares\\Anaconda3\\envs\\test\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36margmax\u001b[1;34m(a, axis, out)\u001b[0m\n\u001b[0;32m   1035\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1036\u001b[0m     \"\"\"\n\u001b[1;32m-> 1037\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'argmax'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1038\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1039\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Softwares\\Anaconda3\\envs\\test\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[1;31m# An AttributeError occurs if the object does not have\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAxisError\u001b[0m: axis 1 is out of bounds for array of dimension 1"
     ]
    }
   ],
   "source": [
    "ID_values[:, 1] = np.argmax(np.mean(np.squeeze(fold5), 0), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 100000, 9)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate([np.array(fold5)*0.6, fold5182*0.4], 0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fold5 = np.load(\"./results/0706_FL_visitres110_4fold_lr28_03washing_v0_batch256_results.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fold5 = np.load(\"./results/0702mixed_pre_seresnext5032x4d_110_5fold0_results.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 100000, 9)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fold5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.42776355, 0.31308624, 0.03723255, ..., 0.15021929, 0.18582086,\n",
       "        0.40452045],\n",
       "       [0.37840018, 0.23903736, 0.39813834, ..., 0.33415744, 0.07246536,\n",
       "        0.07959073],\n",
       "       [0.3605524 , 0.31340173, 0.36258337, ..., 0.32737014, 0.04437453,\n",
       "        0.05203919],\n",
       "       ...,\n",
       "       [0.44522658, 0.3078219 , 0.18811916, ..., 0.06350409, 0.1374954 ,\n",
       "        0.1379186 ],\n",
       "       [0.44269735, 0.36306387, 0.16742909, ..., 0.22216186, 0.12501398,\n",
       "        0.12077025],\n",
       "       [0.44343403, 0.24962471, 0.06397949, ..., 0.33284593, 0.16351128,\n",
       "        0.19103773]], dtype=float32)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(fold5, 0)*0.45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 9)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_result = np.load(\"./fusion/0712_lgb_fe_test_meanfold_overfit.npy\")\n",
    "lgb_result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ID_values[:, 1] = np.argmax(np.mean(np.array([fold5*0.24, result*0.19, fold5182*0.47, lgb_result*0.10]), 0), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ID_values[:, 1] = np.argmax(np.mean(np.array([fold5*0.4, fold5182*0.6]), 0), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ID_values[:, 1] = np.argmax(fold5, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['./dataset/final_test/000000.jpg', 0],\n",
       "       ['./dataset/final_test/000001.jpg', 6],\n",
       "       ['./dataset/final_test/000002.jpg', 0],\n",
       "       ...,\n",
       "       ['./dataset/final_test/099997.jpg', 0],\n",
       "       ['./dataset/final_test/099998.jpg', 0],\n",
       "       ['./dataset/final_test/099999.jpg', 0]], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ID_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"./submit/0702_mixed_pre_CE_182vpseresnext5032x4dv0-110+72426vp_5fold_results0519_adjlr_ensemble64_tta.txt\", \"w\") as f:\n",
    "    for ID, pred in ID_values:\n",
    "        f.write(\"%s \\t %03d\\n\"%(os.path.basename(ID)[:-4], pred+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"./submit/0712_pre_CE_seresnext5032x4dv0-110_5fold+bestacc_meow_senet+CE_182same+lgb_40252015_tta.txt\", \"w\") as f:\n",
    "    for ID, pred in ID_values:\n",
    "        f.write(\"%s \\t %03d\\n\"%(os.path.basename(ID)[:-4], pred+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"./submit/0717_pre_CE_seresnext5032x4dv0-110_5fold_addcs_tta.txt\", \"w\") as f:\n",
    "    for ID, pred in ID_values:\n",
    "        f.write(\"%s \\t %03d\\n\"%(os.path.basename(ID)[:-4], pred+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"./submit/0728_pre_CE_seresnext5032x4dv0_5fold_img192_tta.txt\", \"w\") as f:\n",
    "    for ID, pred in ID_values:\n",
    "        f.write(\"%s \\t %03d\\n\"%(os.path.basename(ID)[:-4], pred+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = pd.read_csv(\"./temp/final_X_tr2.csv\")\n",
    "b = pd.read_csv(\"./temp/image_X_tr2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id_x           True\n",
       "Target         True\n",
       "black_ratio    True\n",
       "basename       True\n",
       "Id_y           True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(a == b).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 95942,\n",
       " 1: 72575,\n",
       " 2: 40578,\n",
       " 3: 5264,\n",
       " 4: 13194,\n",
       " 5: 49934,\n",
       " 6: 16861,\n",
       " 7: 10528,\n",
       " 8: 14051}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(b.loc[b.black_ratio<0.3, \"Target\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b = pd.read_csv(\"./temp/final_X_tr2.csv\")\n",
    "b_i = dict(b.loc[b.black_ratio<0.3, \"Target\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c = pd.read_csv(\"./temp/final_X_val2.csv\")\n",
    "c_i = dict(c.loc[c.black_ratio<0.3, \"Target\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96209/23712 -- 4.057397098515519\n",
      "72473/18256 -- 3.969818141980719\n",
      "40837/10054 -- 4.061766461110006\n",
      "5184/1379 -- 3.75924583031182\n",
      "13161/3271 -- 4.023540201773158\n",
      "50003/12505 -- 3.998640543782487\n",
      "16760/4300 -- 3.8976744186046512\n",
      "10494/2641 -- 3.9734948882998866\n",
      "13806/3614 -- 3.820143884892086\n"
     ]
    }
   ],
   "source": [
    "for i in range(9):\n",
    "    print(\"%s/%s\"%(b_i[i], c_i[i]), \"--\", b_i[i]/c_i[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m_name = \"seresnext5032x4d-FLlog-03washing-lr28-v0-final-batch256\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    best_model = torch.load(\"%s/%s_fold_%s_model_best_loss.pth.tar\"%(config.best_models, m_name, str(i)))\n",
    "    torch.save(best_model[\"state_dict\"], \"%s_fold_%s_model_best_loss.pth.tar\"%( m_name, str(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_model = torch.load(\"%s_fold_%s_model_best_loss.pth.tar\"%(m_name, str(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['module.layer0.conv1.weight', 'module.layer0.bn1.weight', 'module.layer0.bn1.bias', 'module.layer0.bn1.running_mean', 'module.layer0.bn1.running_var', 'module.layer0.bn1.num_batches_tracked', 'module.layer1.0.conv1.weight', 'module.layer1.0.bn1.weight', 'module.layer1.0.bn1.bias', 'module.layer1.0.bn1.running_mean', 'module.layer1.0.bn1.running_var', 'module.layer1.0.bn1.num_batches_tracked', 'module.layer1.0.conv2.weight', 'module.layer1.0.bn2.weight', 'module.layer1.0.bn2.bias', 'module.layer1.0.bn2.running_mean', 'module.layer1.0.bn2.running_var', 'module.layer1.0.bn2.num_batches_tracked', 'module.layer1.0.conv3.weight', 'module.layer1.0.bn3.weight', 'module.layer1.0.bn3.bias', 'module.layer1.0.bn3.running_mean', 'module.layer1.0.bn3.running_var', 'module.layer1.0.bn3.num_batches_tracked', 'module.layer1.0.se_module.fc1.weight', 'module.layer1.0.se_module.fc1.bias', 'module.layer1.0.se_module.fc2.weight', 'module.layer1.0.se_module.fc2.bias', 'module.layer1.0.downsample.0.weight', 'module.layer1.0.downsample.1.weight', 'module.layer1.0.downsample.1.bias', 'module.layer1.0.downsample.1.running_mean', 'module.layer1.0.downsample.1.running_var', 'module.layer1.0.downsample.1.num_batches_tracked', 'module.layer1.1.conv1.weight', 'module.layer1.1.bn1.weight', 'module.layer1.1.bn1.bias', 'module.layer1.1.bn1.running_mean', 'module.layer1.1.bn1.running_var', 'module.layer1.1.bn1.num_batches_tracked', 'module.layer1.1.conv2.weight', 'module.layer1.1.bn2.weight', 'module.layer1.1.bn2.bias', 'module.layer1.1.bn2.running_mean', 'module.layer1.1.bn2.running_var', 'module.layer1.1.bn2.num_batches_tracked', 'module.layer1.1.conv3.weight', 'module.layer1.1.bn3.weight', 'module.layer1.1.bn3.bias', 'module.layer1.1.bn3.running_mean', 'module.layer1.1.bn3.running_var', 'module.layer1.1.bn3.num_batches_tracked', 'module.layer1.1.se_module.fc1.weight', 'module.layer1.1.se_module.fc1.bias', 'module.layer1.1.se_module.fc2.weight', 'module.layer1.1.se_module.fc2.bias', 'module.layer1.2.conv1.weight', 'module.layer1.2.bn1.weight', 'module.layer1.2.bn1.bias', 'module.layer1.2.bn1.running_mean', 'module.layer1.2.bn1.running_var', 'module.layer1.2.bn1.num_batches_tracked', 'module.layer1.2.conv2.weight', 'module.layer1.2.bn2.weight', 'module.layer1.2.bn2.bias', 'module.layer1.2.bn2.running_mean', 'module.layer1.2.bn2.running_var', 'module.layer1.2.bn2.num_batches_tracked', 'module.layer1.2.conv3.weight', 'module.layer1.2.bn3.weight', 'module.layer1.2.bn3.bias', 'module.layer1.2.bn3.running_mean', 'module.layer1.2.bn3.running_var', 'module.layer1.2.bn3.num_batches_tracked', 'module.layer1.2.se_module.fc1.weight', 'module.layer1.2.se_module.fc1.bias', 'module.layer1.2.se_module.fc2.weight', 'module.layer1.2.se_module.fc2.bias', 'module.layer2.0.conv1.weight', 'module.layer2.0.bn1.weight', 'module.layer2.0.bn1.bias', 'module.layer2.0.bn1.running_mean', 'module.layer2.0.bn1.running_var', 'module.layer2.0.bn1.num_batches_tracked', 'module.layer2.0.conv2.weight', 'module.layer2.0.bn2.weight', 'module.layer2.0.bn2.bias', 'module.layer2.0.bn2.running_mean', 'module.layer2.0.bn2.running_var', 'module.layer2.0.bn2.num_batches_tracked', 'module.layer2.0.conv3.weight', 'module.layer2.0.bn3.weight', 'module.layer2.0.bn3.bias', 'module.layer2.0.bn3.running_mean', 'module.layer2.0.bn3.running_var', 'module.layer2.0.bn3.num_batches_tracked', 'module.layer2.0.se_module.fc1.weight', 'module.layer2.0.se_module.fc1.bias', 'module.layer2.0.se_module.fc2.weight', 'module.layer2.0.se_module.fc2.bias', 'module.layer2.0.downsample.0.weight', 'module.layer2.0.downsample.1.weight', 'module.layer2.0.downsample.1.bias', 'module.layer2.0.downsample.1.running_mean', 'module.layer2.0.downsample.1.running_var', 'module.layer2.0.downsample.1.num_batches_tracked', 'module.layer2.1.conv1.weight', 'module.layer2.1.bn1.weight', 'module.layer2.1.bn1.bias', 'module.layer2.1.bn1.running_mean', 'module.layer2.1.bn1.running_var', 'module.layer2.1.bn1.num_batches_tracked', 'module.layer2.1.conv2.weight', 'module.layer2.1.bn2.weight', 'module.layer2.1.bn2.bias', 'module.layer2.1.bn2.running_mean', 'module.layer2.1.bn2.running_var', 'module.layer2.1.bn2.num_batches_tracked', 'module.layer2.1.conv3.weight', 'module.layer2.1.bn3.weight', 'module.layer2.1.bn3.bias', 'module.layer2.1.bn3.running_mean', 'module.layer2.1.bn3.running_var', 'module.layer2.1.bn3.num_batches_tracked', 'module.layer2.1.se_module.fc1.weight', 'module.layer2.1.se_module.fc1.bias', 'module.layer2.1.se_module.fc2.weight', 'module.layer2.1.se_module.fc2.bias', 'module.layer2.2.conv1.weight', 'module.layer2.2.bn1.weight', 'module.layer2.2.bn1.bias', 'module.layer2.2.bn1.running_mean', 'module.layer2.2.bn1.running_var', 'module.layer2.2.bn1.num_batches_tracked', 'module.layer2.2.conv2.weight', 'module.layer2.2.bn2.weight', 'module.layer2.2.bn2.bias', 'module.layer2.2.bn2.running_mean', 'module.layer2.2.bn2.running_var', 'module.layer2.2.bn2.num_batches_tracked', 'module.layer2.2.conv3.weight', 'module.layer2.2.bn3.weight', 'module.layer2.2.bn3.bias', 'module.layer2.2.bn3.running_mean', 'module.layer2.2.bn3.running_var', 'module.layer2.2.bn3.num_batches_tracked', 'module.layer2.2.se_module.fc1.weight', 'module.layer2.2.se_module.fc1.bias', 'module.layer2.2.se_module.fc2.weight', 'module.layer2.2.se_module.fc2.bias', 'module.layer2.3.conv1.weight', 'module.layer2.3.bn1.weight', 'module.layer2.3.bn1.bias', 'module.layer2.3.bn1.running_mean', 'module.layer2.3.bn1.running_var', 'module.layer2.3.bn1.num_batches_tracked', 'module.layer2.3.conv2.weight', 'module.layer2.3.bn2.weight', 'module.layer2.3.bn2.bias', 'module.layer2.3.bn2.running_mean', 'module.layer2.3.bn2.running_var', 'module.layer2.3.bn2.num_batches_tracked', 'module.layer2.3.conv3.weight', 'module.layer2.3.bn3.weight', 'module.layer2.3.bn3.bias', 'module.layer2.3.bn3.running_mean', 'module.layer2.3.bn3.running_var', 'module.layer2.3.bn3.num_batches_tracked', 'module.layer2.3.se_module.fc1.weight', 'module.layer2.3.se_module.fc1.bias', 'module.layer2.3.se_module.fc2.weight', 'module.layer2.3.se_module.fc2.bias', 'module.layer3.0.conv1.weight', 'module.layer3.0.bn1.weight', 'module.layer3.0.bn1.bias', 'module.layer3.0.bn1.running_mean', 'module.layer3.0.bn1.running_var', 'module.layer3.0.bn1.num_batches_tracked', 'module.layer3.0.conv2.weight', 'module.layer3.0.bn2.weight', 'module.layer3.0.bn2.bias', 'module.layer3.0.bn2.running_mean', 'module.layer3.0.bn2.running_var', 'module.layer3.0.bn2.num_batches_tracked', 'module.layer3.0.conv3.weight', 'module.layer3.0.bn3.weight', 'module.layer3.0.bn3.bias', 'module.layer3.0.bn3.running_mean', 'module.layer3.0.bn3.running_var', 'module.layer3.0.bn3.num_batches_tracked', 'module.layer3.0.se_module.fc1.weight', 'module.layer3.0.se_module.fc1.bias', 'module.layer3.0.se_module.fc2.weight', 'module.layer3.0.se_module.fc2.bias', 'module.layer3.0.downsample.0.weight', 'module.layer3.0.downsample.1.weight', 'module.layer3.0.downsample.1.bias', 'module.layer3.0.downsample.1.running_mean', 'module.layer3.0.downsample.1.running_var', 'module.layer3.0.downsample.1.num_batches_tracked', 'module.layer3.1.conv1.weight', 'module.layer3.1.bn1.weight', 'module.layer3.1.bn1.bias', 'module.layer3.1.bn1.running_mean', 'module.layer3.1.bn1.running_var', 'module.layer3.1.bn1.num_batches_tracked', 'module.layer3.1.conv2.weight', 'module.layer3.1.bn2.weight', 'module.layer3.1.bn2.bias', 'module.layer3.1.bn2.running_mean', 'module.layer3.1.bn2.running_var', 'module.layer3.1.bn2.num_batches_tracked', 'module.layer3.1.conv3.weight', 'module.layer3.1.bn3.weight', 'module.layer3.1.bn3.bias', 'module.layer3.1.bn3.running_mean', 'module.layer3.1.bn3.running_var', 'module.layer3.1.bn3.num_batches_tracked', 'module.layer3.1.se_module.fc1.weight', 'module.layer3.1.se_module.fc1.bias', 'module.layer3.1.se_module.fc2.weight', 'module.layer3.1.se_module.fc2.bias', 'module.layer3.2.conv1.weight', 'module.layer3.2.bn1.weight', 'module.layer3.2.bn1.bias', 'module.layer3.2.bn1.running_mean', 'module.layer3.2.bn1.running_var', 'module.layer3.2.bn1.num_batches_tracked', 'module.layer3.2.conv2.weight', 'module.layer3.2.bn2.weight', 'module.layer3.2.bn2.bias', 'module.layer3.2.bn2.running_mean', 'module.layer3.2.bn2.running_var', 'module.layer3.2.bn2.num_batches_tracked', 'module.layer3.2.conv3.weight', 'module.layer3.2.bn3.weight', 'module.layer3.2.bn3.bias', 'module.layer3.2.bn3.running_mean', 'module.layer3.2.bn3.running_var', 'module.layer3.2.bn3.num_batches_tracked', 'module.layer3.2.se_module.fc1.weight', 'module.layer3.2.se_module.fc1.bias', 'module.layer3.2.se_module.fc2.weight', 'module.layer3.2.se_module.fc2.bias', 'module.layer3.3.conv1.weight', 'module.layer3.3.bn1.weight', 'module.layer3.3.bn1.bias', 'module.layer3.3.bn1.running_mean', 'module.layer3.3.bn1.running_var', 'module.layer3.3.bn1.num_batches_tracked', 'module.layer3.3.conv2.weight', 'module.layer3.3.bn2.weight', 'module.layer3.3.bn2.bias', 'module.layer3.3.bn2.running_mean', 'module.layer3.3.bn2.running_var', 'module.layer3.3.bn2.num_batches_tracked', 'module.layer3.3.conv3.weight', 'module.layer3.3.bn3.weight', 'module.layer3.3.bn3.bias', 'module.layer3.3.bn3.running_mean', 'module.layer3.3.bn3.running_var', 'module.layer3.3.bn3.num_batches_tracked', 'module.layer3.3.se_module.fc1.weight', 'module.layer3.3.se_module.fc1.bias', 'module.layer3.3.se_module.fc2.weight', 'module.layer3.3.se_module.fc2.bias', 'module.layer3.4.conv1.weight', 'module.layer3.4.bn1.weight', 'module.layer3.4.bn1.bias', 'module.layer3.4.bn1.running_mean', 'module.layer3.4.bn1.running_var', 'module.layer3.4.bn1.num_batches_tracked', 'module.layer3.4.conv2.weight', 'module.layer3.4.bn2.weight', 'module.layer3.4.bn2.bias', 'module.layer3.4.bn2.running_mean', 'module.layer3.4.bn2.running_var', 'module.layer3.4.bn2.num_batches_tracked', 'module.layer3.4.conv3.weight', 'module.layer3.4.bn3.weight', 'module.layer3.4.bn3.bias', 'module.layer3.4.bn3.running_mean', 'module.layer3.4.bn3.running_var', 'module.layer3.4.bn3.num_batches_tracked', 'module.layer3.4.se_module.fc1.weight', 'module.layer3.4.se_module.fc1.bias', 'module.layer3.4.se_module.fc2.weight', 'module.layer3.4.se_module.fc2.bias', 'module.layer3.5.conv1.weight', 'module.layer3.5.bn1.weight', 'module.layer3.5.bn1.bias', 'module.layer3.5.bn1.running_mean', 'module.layer3.5.bn1.running_var', 'module.layer3.5.bn1.num_batches_tracked', 'module.layer3.5.conv2.weight', 'module.layer3.5.bn2.weight', 'module.layer3.5.bn2.bias', 'module.layer3.5.bn2.running_mean', 'module.layer3.5.bn2.running_var', 'module.layer3.5.bn2.num_batches_tracked', 'module.layer3.5.conv3.weight', 'module.layer3.5.bn3.weight', 'module.layer3.5.bn3.bias', 'module.layer3.5.bn3.running_mean', 'module.layer3.5.bn3.running_var', 'module.layer3.5.bn3.num_batches_tracked', 'module.layer3.5.se_module.fc1.weight', 'module.layer3.5.se_module.fc1.bias', 'module.layer3.5.se_module.fc2.weight', 'module.layer3.5.se_module.fc2.bias', 'module.layer4.0.conv1.weight', 'module.layer4.0.bn1.weight', 'module.layer4.0.bn1.bias', 'module.layer4.0.bn1.running_mean', 'module.layer4.0.bn1.running_var', 'module.layer4.0.bn1.num_batches_tracked', 'module.layer4.0.conv2.weight', 'module.layer4.0.bn2.weight', 'module.layer4.0.bn2.bias', 'module.layer4.0.bn2.running_mean', 'module.layer4.0.bn2.running_var', 'module.layer4.0.bn2.num_batches_tracked', 'module.layer4.0.conv3.weight', 'module.layer4.0.bn3.weight', 'module.layer4.0.bn3.bias', 'module.layer4.0.bn3.running_mean', 'module.layer4.0.bn3.running_var', 'module.layer4.0.bn3.num_batches_tracked', 'module.layer4.0.se_module.fc1.weight', 'module.layer4.0.se_module.fc1.bias', 'module.layer4.0.se_module.fc2.weight', 'module.layer4.0.se_module.fc2.bias', 'module.layer4.0.downsample.0.weight', 'module.layer4.0.downsample.1.weight', 'module.layer4.0.downsample.1.bias', 'module.layer4.0.downsample.1.running_mean', 'module.layer4.0.downsample.1.running_var', 'module.layer4.0.downsample.1.num_batches_tracked', 'module.layer4.1.conv1.weight', 'module.layer4.1.bn1.weight', 'module.layer4.1.bn1.bias', 'module.layer4.1.bn1.running_mean', 'module.layer4.1.bn1.running_var', 'module.layer4.1.bn1.num_batches_tracked', 'module.layer4.1.conv2.weight', 'module.layer4.1.bn2.weight', 'module.layer4.1.bn2.bias', 'module.layer4.1.bn2.running_mean', 'module.layer4.1.bn2.running_var', 'module.layer4.1.bn2.num_batches_tracked', 'module.layer4.1.conv3.weight', 'module.layer4.1.bn3.weight', 'module.layer4.1.bn3.bias', 'module.layer4.1.bn3.running_mean', 'module.layer4.1.bn3.running_var', 'module.layer4.1.bn3.num_batches_tracked', 'module.layer4.1.se_module.fc1.weight', 'module.layer4.1.se_module.fc1.bias', 'module.layer4.1.se_module.fc2.weight', 'module.layer4.1.se_module.fc2.bias', 'module.layer4.2.conv1.weight', 'module.layer4.2.bn1.weight', 'module.layer4.2.bn1.bias', 'module.layer4.2.bn1.running_mean', 'module.layer4.2.bn1.running_var', 'module.layer4.2.bn1.num_batches_tracked', 'module.layer4.2.conv2.weight', 'module.layer4.2.bn2.weight', 'module.layer4.2.bn2.bias', 'module.layer4.2.bn2.running_mean', 'module.layer4.2.bn2.running_var', 'module.layer4.2.bn2.num_batches_tracked', 'module.layer4.2.conv3.weight', 'module.layer4.2.bn3.weight', 'module.layer4.2.bn3.bias', 'module.layer4.2.bn3.running_mean', 'module.layer4.2.bn3.running_var', 'module.layer4.2.bn3.num_batches_tracked', 'module.layer4.2.se_module.fc1.weight', 'module.layer4.2.se_module.fc1.bias', 'module.layer4.2.se_module.fc2.weight', 'module.layer4.2.se_module.fc2.bias', 'module.last_linear.0.weight', 'module.last_linear.0.bias'])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding:utf-8 -*-\n",
    "# Author: Xiangtai Li(lxtpku@pku.edu.cn)\n",
    "# Pytorch Implementation of Octave Conv Operation\n",
    "# This version use nn.Conv2d because alpha_in always equals alpha_out\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class OctaveConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, alpha=0.5, stride=1, padding=1, dilation=1,\n",
    "                 groups=1, bias=False):\n",
    "        super(OctaveConv, self).__init__()\n",
    "        kernel_size = kernel_size[0]\n",
    "        self.h2g_pool = nn.AvgPool2d(kernel_size=(2, 2), stride=2)\n",
    "        self.upsample = torch.nn.Upsample(scale_factor=2, mode='nearest')\n",
    "        self.stride = stride\n",
    "        self.l2l = torch.nn.Conv2d(int(alpha * in_channels), int(alpha * out_channels),\n",
    "                                   kernel_size, 1, padding, dilation, groups, bias)\n",
    "        self.l2h = torch.nn.Conv2d(int(alpha * in_channels), out_channels - int(alpha * out_channels),\n",
    "                                   kernel_size, 1, padding, dilation, groups, bias)\n",
    "        self.h2l = torch.nn.Conv2d(in_channels - int(alpha * in_channels), int(alpha * out_channels),\n",
    "                                   kernel_size, 1, padding, dilation, groups, bias)\n",
    "        self.h2h = torch.nn.Conv2d(in_channels - int(alpha * in_channels),\n",
    "                                   out_channels - int(alpha * out_channels),\n",
    "                                   kernel_size, 1, padding, dilation, groups, bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        X_h, X_l = x\n",
    "\n",
    "        if self.stride ==2:\n",
    "            X_h, X_l = self.h2g_pool(X_h), self.h2g_pool(X_l)\n",
    "\n",
    "        X_h2l = self.h2g_pool(X_h)\n",
    "\n",
    "        X_h2h = self.h2h(X_h)\n",
    "        X_l2h = self.l2h(X_l)\n",
    "\n",
    "        X_l2l = self.l2l(X_l)\n",
    "        X_h2l = self.h2l(X_h2l)\n",
    "        \n",
    "        X_l2h = self.upsample(X_l2h)\n",
    "        X_h = X_l2h + X_h2h\n",
    "        X_l = X_h2l + X_l2l\n",
    "\n",
    "        return X_h, X_l\n",
    "\n",
    "\n",
    "class FirstOctaveConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels,kernel_size, alpha=0.5, stride=1, padding=1, dilation=1,\n",
    "                 groups=1, bias=False):\n",
    "        super(FirstOctaveConv, self).__init__()\n",
    "        self.stride = stride\n",
    "        kernel_size = kernel_size[0]\n",
    "        self.h2g_pool = nn.AvgPool2d(kernel_size=(2, 2), stride=2)\n",
    "        self.h2l = torch.nn.Conv2d(in_channels, int(alpha * out_channels),\n",
    "                                   kernel_size, 1, padding, dilation, groups, bias)\n",
    "        self.h2h = torch.nn.Conv2d(in_channels, out_channels - int(alpha * out_channels),\n",
    "                                   kernel_size, 1, padding, dilation, groups, bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.stride ==2:\n",
    "            x = self.h2g_pool(x)\n",
    "\n",
    "        X_h2l = self.h2g_pool(x)\n",
    "        X_h = x\n",
    "        X_h = self.h2h(X_h)\n",
    "        X_l = self.h2l(X_h2l)\n",
    "\n",
    "        return X_h, X_l\n",
    "\n",
    "\n",
    "class LastOctaveConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, alpha=0.5, stride=1, padding=1, dilation=1,\n",
    "                 groups=1, bias=False):\n",
    "        super(LastOctaveConv, self).__init__()\n",
    "        self.stride = stride\n",
    "        kernel_size = kernel_size[0]\n",
    "        self.h2g_pool = nn.AvgPool2d(kernel_size=(2,2), stride=2)\n",
    "\n",
    "        self.l2h = torch.nn.Conv2d(int(alpha * in_channels), out_channels,\n",
    "                                   kernel_size, 1, padding, dilation, groups, bias)\n",
    "        self.h2h = torch.nn.Conv2d(in_channels - int(alpha * in_channels),\n",
    "                                   out_channels,\n",
    "                                   kernel_size, 1, padding, dilation, groups, bias)\n",
    "        self.upsample = torch.nn.Upsample(scale_factor=2, mode='nearest')\n",
    "\n",
    "    def forward(self, x):\n",
    "        X_h, X_l = x\n",
    "\n",
    "        if self.stride ==2:\n",
    "            X_h, X_l = self.h2g_pool(X_h), self.h2g_pool(X_l)\n",
    "\n",
    "        X_l2h = self.l2h(X_l)\n",
    "        X_h2h = self.h2h(X_h)\n",
    "        X_l2h = self.upsample(X_l2h)\n",
    "        \n",
    "        X_h = X_h2h + X_l2h\n",
    "\n",
    "        return X_h\n",
    "\n",
    "\n",
    "class OctaveCBR(nn.Module):\n",
    "    def __init__(self,in_channels, out_channels, kernel_size=(3,3),alpha=0.5, stride=1, padding=1, dilation=1,\n",
    "                 groups=1, bias=False, norm_layer=nn.BatchNorm2d):\n",
    "        super(OctaveCBR, self).__init__()\n",
    "        self.conv = OctaveConv(in_channels,out_channels,kernel_size, alpha, stride, padding, dilation, groups, bias)\n",
    "        self.bn_h = norm_layer(int(out_channels*(1-alpha)))\n",
    "        self.bn_l = norm_layer(int(out_channels*alpha))\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_h, x_l = self.conv(x)\n",
    "        x_h = self.relu(self.bn_h(x_h))\n",
    "        x_l = self.relu(self.bn_l(x_l))\n",
    "        return x_h, x_l\n",
    "\n",
    "\n",
    "class OctaveCB(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=(3,3), alpha=0.5, stride=1, padding=1, dilation=1,\n",
    "                 groups=1, bias=False, norm_layer=nn.BatchNorm2d):\n",
    "        super(OctaveCB, self).__init__()\n",
    "        self.conv = OctaveConv(in_channels, out_channels, kernel_size, alpha, stride, padding, dilation,\n",
    "                               groups, bias)\n",
    "        self.bn_h = norm_layer(int(out_channels * (1 - alpha)))\n",
    "        self.bn_l = norm_layer(int(out_channels * alpha))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_h, x_l = self.conv(x)\n",
    "        x_h = self.bn_h(x_h)\n",
    "        x_l = self.bn_l(x_l)\n",
    "        return x_h, x_l\n",
    "\n",
    "\n",
    "class FirstOctaveCBR(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=(3,3),alpha=0.5, stride=1, padding=1, dilation=1,\n",
    "                 groups=1, bias=False,norm_layer=nn.BatchNorm2d):\n",
    "        super(FirstOctaveCBR, self).__init__()\n",
    "        self.conv = FirstOctaveConv(in_channels,out_channels,kernel_size, alpha,stride,padding,dilation,groups,bias)\n",
    "        self.bn_h = norm_layer(int(out_channels * (1 - alpha)))\n",
    "        self.bn_l = norm_layer(int(out_channels * alpha))\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_h, x_l = self.conv(x)\n",
    "        x_h = self.relu(self.bn_h(x_h))\n",
    "        x_l = self.relu(self.bn_l(x_l))\n",
    "        return x_h, x_l\n",
    "\n",
    "\n",
    "class LastOCtaveCBR(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=(3,3), alpha=0.5, stride=1, padding=1, dilation=1,\n",
    "                 groups=1, bias=False, norm_layer=nn.BatchNorm2d):\n",
    "        super(LastOCtaveCBR, self).__init__()\n",
    "        self.conv = LastOctaveConv(in_channels, out_channels, kernel_size, alpha, stride, padding, dilation, groups, bias)\n",
    "        self.bn_h = norm_layer(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_h = self.conv(x)\n",
    "        x_h = self.relu(self.bn_h(x_h))\n",
    "        return x_h\n",
    "\n",
    "\n",
    "class FirstOctaveCB(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=(3,3), alpha=0.5,stride=1, padding=1, dilation=1,\n",
    "                 groups=1, bias=False, norm_layer=nn.BatchNorm2d):\n",
    "        super(FirstOctaveCB, self).__init__()\n",
    "        self.conv = FirstOctaveConv(in_channels,out_channels,kernel_size, alpha,stride,padding,dilation,groups,bias)\n",
    "        self.bn_h = norm_layer(int(out_channels * (1 - alpha)))\n",
    "        self.bn_l = norm_layer(int(out_channels * alpha))\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_h, x_l = self.conv(x)\n",
    "        x_h = self.bn_h(x_h)\n",
    "        x_l = self.bn_l(x_l)\n",
    "        return x_h, x_l\n",
    "\n",
    "\n",
    "class LastOCtaveCB(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, alpha=0.5, stride=1, padding=1, dilation=1,\n",
    "                 groups=1, bias=False, norm_layer=nn.BatchNorm2d):\n",
    "        super(LastOCtaveCB, self).__init__()\n",
    "        self.conv = LastOctaveConv( in_channels, out_channels, kernel_size, alpha, stride, padding, dilation, groups, bias)\n",
    "        self.bn_h = norm_layer(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_h = self.conv(x)\n",
    "        x_h = self.bn_h(x_h)\n",
    "        return x_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class OctaveConv_1(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, alpha_in=0.5, alpha_out=0.5, stride=1, padding=0, dilation=1,\n",
    "                 groups=1, bias=False):\n",
    "        super(OctaveConv, self).__init__()\n",
    "        self.downsample = nn.AvgPool2d(kernel_size=(2, 2), stride=2)\n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "        assert stride == 1 or stride == 2, \"Stride should be 1 or 2.\"\n",
    "        self.stride = stride\n",
    "        assert 0 <= alpha_in <= 1 and 0 <= alpha_out <= 1, \"Alphas should be in the interval from 0 to 1.\"\n",
    "        self.alpha_in, self.alpha_out = alpha_in, alpha_out\n",
    "        self.conv_l2l = None if alpha_in == 0 or alpha_out == 0 else \\\n",
    "                        nn.Conv2d(int(alpha_in * in_channels), int(alpha_out * out_channels),\n",
    "                                  kernel_size, 1, padding, dilation, groups, bias)\n",
    "        self.conv_l2h = None if alpha_in == 0 or alpha_out == 1 else \\\n",
    "                        nn.Conv2d(int(alpha_in * in_channels), out_channels - int(alpha_out * out_channels),\n",
    "                                  kernel_size, 1, padding, dilation, groups, bias)\n",
    "        self.conv_h2l = None if alpha_in == 1 or alpha_out == 0 else \\\n",
    "                        nn.Conv2d(in_channels - int(alpha_in * in_channels), int(alpha_out * out_channels),\n",
    "                                  kernel_size, 1, padding, dilation, groups, bias)\n",
    "        self.conv_h2h = None if alpha_in == 1 or alpha_out == 1 else \\\n",
    "                        nn.Conv2d(in_channels - int(alpha_in * in_channels), out_channels - int(alpha_out * out_channels),\n",
    "                                  kernel_size, 1, padding, dilation, groups, bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_h, x_l = x if type(x) is tuple else (x, None)\n",
    "\n",
    "        if x_h is not None:\n",
    "            x_h = self.downsample(x_h) if self.stride == 2 else x_h\n",
    "            x_h2h = self.conv_h2h(x_h)\n",
    "            x_h2l = self.conv_h2l(self.downsample(x_h)) if self.alpha_out > 0 else None\n",
    "        if x_l is not None:\n",
    "            x_l2h = self.conv_l2h(x_l)\n",
    "            x_l2h = self.upsample(x_l2h) if self.stride == 1 else x_l2h\n",
    "            x_l2l = self.downsample(x_l) if self.stride == 2 else x_l\n",
    "            x_l2l = self.conv_l2l(x_l2l) if self.alpha_out > 0 else None \n",
    "            x_h = x_l2h + x_h2h\n",
    "            x_l = x_h2l + x_l2l if x_h2l is not None and x_l2l is not None else None\n",
    "            return x_h, x_l\n",
    "        else:\n",
    "            return x_h2h, x_h2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "super(type, obj): obj must be an instance or subtype of type",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-c63654053930>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mFOCconv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOctaveConv_1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkernel_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0min_channels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_channels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mx_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFOCconv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"First: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_out\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_out\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-55daeba3d29f>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, in_channels, out_channels, kernel_size, alpha_in, alpha_out, stride, padding, dilation, groups, bias)\u001b[0m\n\u001b[0;32m      2\u001b[0m     def __init__(self, in_channels, out_channels, kernel_size, alpha_in=0.5, alpha_out=0.5, stride=1, padding=0, dilation=1,\n\u001b[0;32m      3\u001b[0m                  groups=1, bias=False):\n\u001b[1;32m----> 4\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mOctaveConv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdownsample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAvgPool2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkernel_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupsample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUpsample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscale_factor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'nearest'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: super(type, obj): obj must be an instance or subtype of type"
     ]
    }
   ],
   "source": [
    "FOCconv = OctaveConv_1(kernel_size=3, in_channels=3, out_channels=128).cuda()\n",
    "x_out, y_out = FOCconv(i)\n",
    "print(\"First: \", x_out.size(), y_out.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 128, 16, 16])\n",
      "torch.Size([1, 384, 8, 8])\n",
      "First:  torch.Size([1, 64, 24, 182]) torch.Size([1, 64, 12, 91])\n",
      "Last:  torch.Size([1, 128, 32, 32])\n",
      "OCB: torch.Size([1, 32, 32, 32]) torch.Size([1, 96, 16, 16])\n",
      "Last OCB torch.Size([1, 128, 32, 32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Softwares\\Anaconda3\\envs\\test\\lib\\site-packages\\torch\\nn\\modules\\upsampling.py:122: UserWarning: nn.Upsampling is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.Upsampling is deprecated. Use nn.functional.interpolate instead.\")\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # nn.Conv2d\n",
    "    high = torch.Tensor(1, 64, 32, 32).cuda()\n",
    "    low = torch.Tensor(1, 192, 16, 16).cuda()\n",
    "    # test Oc conv\n",
    "    OCconv = OctaveConv(kernel_size=(3,3),in_channels=256,out_channels=512,bias=False,stride=2,alpha=0.75).cuda()\n",
    "    i = high,low\n",
    "    x_out,y_out = OCconv(i)\n",
    "    print(x_out.size())\n",
    "    print(y_out.size())\n",
    "\n",
    "    i = torch.Tensor(1, 3, 24, 182).cuda()\n",
    "    FOCconv = FirstOctaveConv(kernel_size=(3, 3), in_channels=3, out_channels=128).cuda()\n",
    "    x_out, y_out = FOCconv(i)\n",
    "    print(\"First: \", x_out.size(), y_out.size())\n",
    "    # test last Octave Cov\n",
    "    LOCconv = LastOctaveConv(kernel_size=(3, 3), in_channels=256, out_channels=128, alpha=0.75).cuda()\n",
    "    i = high, low\n",
    "    out = LOCconv(i)\n",
    "    print(\"Last: \", out.size())\n",
    "\n",
    "    # test OCB\n",
    "    ocb = OctaveCB(in_channels=256, out_channels=128, alpha=0.75).cuda()\n",
    "    i = high, low\n",
    "    x_out_h, y_out_l = ocb(i)\n",
    "    print(\"OCB:\",x_out_h.size(),y_out_l.size())\n",
    "\n",
    "    # test last OCB\n",
    "    ocb_last = LastOCtaveCBR(256, 128, alpha=0.75).cuda()\n",
    "    i = high, low\n",
    "    x_out_h = ocb_last(i)\n",
    "    print(\"Last OCB\", x_out_h.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from models.oct_resnet import oct_resnet110, oct_resnet50\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from models.resnet4cifar import resnet110"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\DL\\LiZeda\\InterestingProjects\\competition\\bd\\models\\resnet4cifar.py:38: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  init.kaiming_normal(m.weight)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 16, 224, 224]             432\n",
      "       BatchNorm2d-2         [-1, 16, 224, 224]              32\n",
      "              ReLU-3         [-1, 16, 224, 224]               0\n",
      "            Conv2d-4         [-1, 16, 224, 224]           2,304\n",
      "       BatchNorm2d-5         [-1, 16, 224, 224]              32\n",
      "            Conv2d-6         [-1, 16, 224, 224]           2,304\n",
      "       BatchNorm2d-7         [-1, 16, 224, 224]              32\n",
      "        BasicBlock-8         [-1, 16, 224, 224]               0\n",
      "            Conv2d-9         [-1, 16, 224, 224]           2,304\n",
      "      BatchNorm2d-10         [-1, 16, 224, 224]              32\n",
      "           Conv2d-11         [-1, 16, 224, 224]           2,304\n",
      "      BatchNorm2d-12         [-1, 16, 224, 224]              32\n",
      "       BasicBlock-13         [-1, 16, 224, 224]               0\n",
      "           Conv2d-14         [-1, 16, 224, 224]           2,304\n",
      "      BatchNorm2d-15         [-1, 16, 224, 224]              32\n",
      "           Conv2d-16         [-1, 16, 224, 224]           2,304\n",
      "      BatchNorm2d-17         [-1, 16, 224, 224]              32\n",
      "       BasicBlock-18         [-1, 16, 224, 224]               0\n",
      "           Conv2d-19         [-1, 16, 224, 224]           2,304\n",
      "      BatchNorm2d-20         [-1, 16, 224, 224]              32\n",
      "           Conv2d-21         [-1, 16, 224, 224]           2,304\n",
      "      BatchNorm2d-22         [-1, 16, 224, 224]              32\n",
      "       BasicBlock-23         [-1, 16, 224, 224]               0\n",
      "           Conv2d-24         [-1, 16, 224, 224]           2,304\n",
      "      BatchNorm2d-25         [-1, 16, 224, 224]              32\n",
      "           Conv2d-26         [-1, 16, 224, 224]           2,304\n",
      "      BatchNorm2d-27         [-1, 16, 224, 224]              32\n",
      "       BasicBlock-28         [-1, 16, 224, 224]               0\n",
      "           Conv2d-29         [-1, 16, 224, 224]           2,304\n",
      "      BatchNorm2d-30         [-1, 16, 224, 224]              32\n",
      "           Conv2d-31         [-1, 16, 224, 224]           2,304\n",
      "      BatchNorm2d-32         [-1, 16, 224, 224]              32\n",
      "       BasicBlock-33         [-1, 16, 224, 224]               0\n",
      "           Conv2d-34         [-1, 16, 224, 224]           2,304\n",
      "      BatchNorm2d-35         [-1, 16, 224, 224]              32\n",
      "           Conv2d-36         [-1, 16, 224, 224]           2,304\n",
      "      BatchNorm2d-37         [-1, 16, 224, 224]              32\n",
      "       BasicBlock-38         [-1, 16, 224, 224]               0\n",
      "           Conv2d-39         [-1, 16, 224, 224]           2,304\n",
      "      BatchNorm2d-40         [-1, 16, 224, 224]              32\n",
      "           Conv2d-41         [-1, 16, 224, 224]           2,304\n",
      "      BatchNorm2d-42         [-1, 16, 224, 224]              32\n",
      "       BasicBlock-43         [-1, 16, 224, 224]               0\n",
      "           Conv2d-44         [-1, 16, 224, 224]           2,304\n",
      "      BatchNorm2d-45         [-1, 16, 224, 224]              32\n",
      "           Conv2d-46         [-1, 16, 224, 224]           2,304\n",
      "      BatchNorm2d-47         [-1, 16, 224, 224]              32\n",
      "       BasicBlock-48         [-1, 16, 224, 224]               0\n",
      "           Conv2d-49         [-1, 16, 224, 224]           2,304\n",
      "      BatchNorm2d-50         [-1, 16, 224, 224]              32\n",
      "           Conv2d-51         [-1, 16, 224, 224]           2,304\n",
      "      BatchNorm2d-52         [-1, 16, 224, 224]              32\n",
      "       BasicBlock-53         [-1, 16, 224, 224]               0\n",
      "           Conv2d-54         [-1, 16, 224, 224]           2,304\n",
      "      BatchNorm2d-55         [-1, 16, 224, 224]              32\n",
      "           Conv2d-56         [-1, 16, 224, 224]           2,304\n",
      "      BatchNorm2d-57         [-1, 16, 224, 224]              32\n",
      "       BasicBlock-58         [-1, 16, 224, 224]               0\n",
      "           Conv2d-59         [-1, 16, 224, 224]           2,304\n",
      "      BatchNorm2d-60         [-1, 16, 224, 224]              32\n",
      "           Conv2d-61         [-1, 16, 224, 224]           2,304\n",
      "      BatchNorm2d-62         [-1, 16, 224, 224]              32\n",
      "       BasicBlock-63         [-1, 16, 224, 224]               0\n",
      "           Conv2d-64         [-1, 16, 224, 224]           2,304\n",
      "      BatchNorm2d-65         [-1, 16, 224, 224]              32\n",
      "           Conv2d-66         [-1, 16, 224, 224]           2,304\n",
      "      BatchNorm2d-67         [-1, 16, 224, 224]              32\n",
      "       BasicBlock-68         [-1, 16, 224, 224]               0\n",
      "           Conv2d-69         [-1, 16, 224, 224]           2,304\n",
      "      BatchNorm2d-70         [-1, 16, 224, 224]              32\n",
      "           Conv2d-71         [-1, 16, 224, 224]           2,304\n",
      "      BatchNorm2d-72         [-1, 16, 224, 224]              32\n",
      "       BasicBlock-73         [-1, 16, 224, 224]               0\n",
      "           Conv2d-74         [-1, 16, 224, 224]           2,304\n",
      "      BatchNorm2d-75         [-1, 16, 224, 224]              32\n",
      "           Conv2d-76         [-1, 16, 224, 224]           2,304\n",
      "      BatchNorm2d-77         [-1, 16, 224, 224]              32\n",
      "       BasicBlock-78         [-1, 16, 224, 224]               0\n",
      "           Conv2d-79         [-1, 16, 224, 224]           2,304\n",
      "      BatchNorm2d-80         [-1, 16, 224, 224]              32\n",
      "           Conv2d-81         [-1, 16, 224, 224]           2,304\n",
      "      BatchNorm2d-82         [-1, 16, 224, 224]              32\n",
      "       BasicBlock-83         [-1, 16, 224, 224]               0\n",
      "           Conv2d-84         [-1, 16, 224, 224]           2,304\n",
      "      BatchNorm2d-85         [-1, 16, 224, 224]              32\n",
      "           Conv2d-86         [-1, 16, 224, 224]           2,304\n",
      "      BatchNorm2d-87         [-1, 16, 224, 224]              32\n",
      "       BasicBlock-88         [-1, 16, 224, 224]               0\n",
      "           Conv2d-89         [-1, 16, 224, 224]           2,304\n",
      "      BatchNorm2d-90         [-1, 16, 224, 224]              32\n",
      "           Conv2d-91         [-1, 16, 224, 224]           2,304\n",
      "      BatchNorm2d-92         [-1, 16, 224, 224]              32\n",
      "       BasicBlock-93         [-1, 16, 224, 224]               0\n",
      "           Conv2d-94         [-1, 32, 112, 112]           4,608\n",
      "      BatchNorm2d-95         [-1, 32, 112, 112]              64\n",
      "           Conv2d-96         [-1, 32, 112, 112]           9,216\n",
      "      BatchNorm2d-97         [-1, 32, 112, 112]              64\n",
      "      LambdaLayer-98         [-1, 32, 112, 112]               0\n",
      "       BasicBlock-99         [-1, 32, 112, 112]               0\n",
      "          Conv2d-100         [-1, 32, 112, 112]           9,216\n",
      "     BatchNorm2d-101         [-1, 32, 112, 112]              64\n",
      "          Conv2d-102         [-1, 32, 112, 112]           9,216\n",
      "     BatchNorm2d-103         [-1, 32, 112, 112]              64\n",
      "      BasicBlock-104         [-1, 32, 112, 112]               0\n",
      "          Conv2d-105         [-1, 32, 112, 112]           9,216\n",
      "     BatchNorm2d-106         [-1, 32, 112, 112]              64\n",
      "          Conv2d-107         [-1, 32, 112, 112]           9,216\n",
      "     BatchNorm2d-108         [-1, 32, 112, 112]              64\n",
      "      BasicBlock-109         [-1, 32, 112, 112]               0\n",
      "          Conv2d-110         [-1, 32, 112, 112]           9,216\n",
      "     BatchNorm2d-111         [-1, 32, 112, 112]              64\n",
      "          Conv2d-112         [-1, 32, 112, 112]           9,216\n",
      "     BatchNorm2d-113         [-1, 32, 112, 112]              64\n",
      "      BasicBlock-114         [-1, 32, 112, 112]               0\n",
      "          Conv2d-115         [-1, 32, 112, 112]           9,216\n",
      "     BatchNorm2d-116         [-1, 32, 112, 112]              64\n",
      "          Conv2d-117         [-1, 32, 112, 112]           9,216\n",
      "     BatchNorm2d-118         [-1, 32, 112, 112]              64\n",
      "      BasicBlock-119         [-1, 32, 112, 112]               0\n",
      "          Conv2d-120         [-1, 32, 112, 112]           9,216\n",
      "     BatchNorm2d-121         [-1, 32, 112, 112]              64\n",
      "          Conv2d-122         [-1, 32, 112, 112]           9,216\n",
      "     BatchNorm2d-123         [-1, 32, 112, 112]              64\n",
      "      BasicBlock-124         [-1, 32, 112, 112]               0\n",
      "          Conv2d-125         [-1, 32, 112, 112]           9,216\n",
      "     BatchNorm2d-126         [-1, 32, 112, 112]              64\n",
      "          Conv2d-127         [-1, 32, 112, 112]           9,216\n",
      "     BatchNorm2d-128         [-1, 32, 112, 112]              64\n",
      "      BasicBlock-129         [-1, 32, 112, 112]               0\n",
      "          Conv2d-130         [-1, 32, 112, 112]           9,216\n",
      "     BatchNorm2d-131         [-1, 32, 112, 112]              64\n",
      "          Conv2d-132         [-1, 32, 112, 112]           9,216\n",
      "     BatchNorm2d-133         [-1, 32, 112, 112]              64\n",
      "      BasicBlock-134         [-1, 32, 112, 112]               0\n",
      "          Conv2d-135         [-1, 32, 112, 112]           9,216\n",
      "     BatchNorm2d-136         [-1, 32, 112, 112]              64\n",
      "          Conv2d-137         [-1, 32, 112, 112]           9,216\n",
      "     BatchNorm2d-138         [-1, 32, 112, 112]              64\n",
      "      BasicBlock-139         [-1, 32, 112, 112]               0\n",
      "          Conv2d-140         [-1, 32, 112, 112]           9,216\n",
      "     BatchNorm2d-141         [-1, 32, 112, 112]              64\n",
      "          Conv2d-142         [-1, 32, 112, 112]           9,216\n",
      "     BatchNorm2d-143         [-1, 32, 112, 112]              64\n",
      "      BasicBlock-144         [-1, 32, 112, 112]               0\n",
      "          Conv2d-145         [-1, 32, 112, 112]           9,216\n",
      "     BatchNorm2d-146         [-1, 32, 112, 112]              64\n",
      "          Conv2d-147         [-1, 32, 112, 112]           9,216\n",
      "     BatchNorm2d-148         [-1, 32, 112, 112]              64\n",
      "      BasicBlock-149         [-1, 32, 112, 112]               0\n",
      "          Conv2d-150         [-1, 32, 112, 112]           9,216\n",
      "     BatchNorm2d-151         [-1, 32, 112, 112]              64\n",
      "          Conv2d-152         [-1, 32, 112, 112]           9,216\n",
      "     BatchNorm2d-153         [-1, 32, 112, 112]              64\n",
      "      BasicBlock-154         [-1, 32, 112, 112]               0\n",
      "          Conv2d-155         [-1, 32, 112, 112]           9,216\n",
      "     BatchNorm2d-156         [-1, 32, 112, 112]              64\n",
      "          Conv2d-157         [-1, 32, 112, 112]           9,216\n",
      "     BatchNorm2d-158         [-1, 32, 112, 112]              64\n",
      "      BasicBlock-159         [-1, 32, 112, 112]               0\n",
      "          Conv2d-160         [-1, 32, 112, 112]           9,216\n",
      "     BatchNorm2d-161         [-1, 32, 112, 112]              64\n",
      "          Conv2d-162         [-1, 32, 112, 112]           9,216\n",
      "     BatchNorm2d-163         [-1, 32, 112, 112]              64\n",
      "      BasicBlock-164         [-1, 32, 112, 112]               0\n",
      "          Conv2d-165         [-1, 32, 112, 112]           9,216\n",
      "     BatchNorm2d-166         [-1, 32, 112, 112]              64\n",
      "          Conv2d-167         [-1, 32, 112, 112]           9,216\n",
      "     BatchNorm2d-168         [-1, 32, 112, 112]              64\n",
      "      BasicBlock-169         [-1, 32, 112, 112]               0\n",
      "          Conv2d-170         [-1, 32, 112, 112]           9,216\n",
      "     BatchNorm2d-171         [-1, 32, 112, 112]              64\n",
      "          Conv2d-172         [-1, 32, 112, 112]           9,216\n",
      "     BatchNorm2d-173         [-1, 32, 112, 112]              64\n",
      "      BasicBlock-174         [-1, 32, 112, 112]               0\n",
      "          Conv2d-175         [-1, 32, 112, 112]           9,216\n",
      "     BatchNorm2d-176         [-1, 32, 112, 112]              64\n",
      "          Conv2d-177         [-1, 32, 112, 112]           9,216\n",
      "     BatchNorm2d-178         [-1, 32, 112, 112]              64\n",
      "      BasicBlock-179         [-1, 32, 112, 112]               0\n",
      "          Conv2d-180         [-1, 32, 112, 112]           9,216\n",
      "     BatchNorm2d-181         [-1, 32, 112, 112]              64\n",
      "          Conv2d-182         [-1, 32, 112, 112]           9,216\n",
      "     BatchNorm2d-183         [-1, 32, 112, 112]              64\n",
      "      BasicBlock-184         [-1, 32, 112, 112]               0\n",
      "          Conv2d-185           [-1, 64, 56, 56]          18,432\n",
      "     BatchNorm2d-186           [-1, 64, 56, 56]             128\n",
      "          Conv2d-187           [-1, 64, 56, 56]          36,864\n",
      "     BatchNorm2d-188           [-1, 64, 56, 56]             128\n",
      "     LambdaLayer-189           [-1, 64, 56, 56]               0\n",
      "      BasicBlock-190           [-1, 64, 56, 56]               0\n",
      "          Conv2d-191           [-1, 64, 56, 56]          36,864\n",
      "     BatchNorm2d-192           [-1, 64, 56, 56]             128\n",
      "          Conv2d-193           [-1, 64, 56, 56]          36,864\n",
      "     BatchNorm2d-194           [-1, 64, 56, 56]             128\n",
      "      BasicBlock-195           [-1, 64, 56, 56]               0\n",
      "          Conv2d-196           [-1, 64, 56, 56]          36,864\n",
      "     BatchNorm2d-197           [-1, 64, 56, 56]             128\n",
      "          Conv2d-198           [-1, 64, 56, 56]          36,864\n",
      "     BatchNorm2d-199           [-1, 64, 56, 56]             128\n",
      "      BasicBlock-200           [-1, 64, 56, 56]               0\n",
      "          Conv2d-201           [-1, 64, 56, 56]          36,864\n",
      "     BatchNorm2d-202           [-1, 64, 56, 56]             128\n",
      "          Conv2d-203           [-1, 64, 56, 56]          36,864\n",
      "     BatchNorm2d-204           [-1, 64, 56, 56]             128\n",
      "      BasicBlock-205           [-1, 64, 56, 56]               0\n",
      "          Conv2d-206           [-1, 64, 56, 56]          36,864\n",
      "     BatchNorm2d-207           [-1, 64, 56, 56]             128\n",
      "          Conv2d-208           [-1, 64, 56, 56]          36,864\n",
      "     BatchNorm2d-209           [-1, 64, 56, 56]             128\n",
      "      BasicBlock-210           [-1, 64, 56, 56]               0\n",
      "          Conv2d-211           [-1, 64, 56, 56]          36,864\n",
      "     BatchNorm2d-212           [-1, 64, 56, 56]             128\n",
      "          Conv2d-213           [-1, 64, 56, 56]          36,864\n",
      "     BatchNorm2d-214           [-1, 64, 56, 56]             128\n",
      "      BasicBlock-215           [-1, 64, 56, 56]               0\n",
      "          Conv2d-216           [-1, 64, 56, 56]          36,864\n",
      "     BatchNorm2d-217           [-1, 64, 56, 56]             128\n",
      "          Conv2d-218           [-1, 64, 56, 56]          36,864\n",
      "     BatchNorm2d-219           [-1, 64, 56, 56]             128\n",
      "      BasicBlock-220           [-1, 64, 56, 56]               0\n",
      "          Conv2d-221           [-1, 64, 56, 56]          36,864\n",
      "     BatchNorm2d-222           [-1, 64, 56, 56]             128\n",
      "          Conv2d-223           [-1, 64, 56, 56]          36,864\n",
      "     BatchNorm2d-224           [-1, 64, 56, 56]             128\n",
      "      BasicBlock-225           [-1, 64, 56, 56]               0\n",
      "          Conv2d-226           [-1, 64, 56, 56]          36,864\n",
      "     BatchNorm2d-227           [-1, 64, 56, 56]             128\n",
      "          Conv2d-228           [-1, 64, 56, 56]          36,864\n",
      "     BatchNorm2d-229           [-1, 64, 56, 56]             128\n",
      "      BasicBlock-230           [-1, 64, 56, 56]               0\n",
      "          Conv2d-231           [-1, 64, 56, 56]          36,864\n",
      "     BatchNorm2d-232           [-1, 64, 56, 56]             128\n",
      "          Conv2d-233           [-1, 64, 56, 56]          36,864\n",
      "     BatchNorm2d-234           [-1, 64, 56, 56]             128\n",
      "      BasicBlock-235           [-1, 64, 56, 56]               0\n",
      "          Conv2d-236           [-1, 64, 56, 56]          36,864\n",
      "     BatchNorm2d-237           [-1, 64, 56, 56]             128\n",
      "          Conv2d-238           [-1, 64, 56, 56]          36,864\n",
      "     BatchNorm2d-239           [-1, 64, 56, 56]             128\n",
      "      BasicBlock-240           [-1, 64, 56, 56]               0\n",
      "          Conv2d-241           [-1, 64, 56, 56]          36,864\n",
      "     BatchNorm2d-242           [-1, 64, 56, 56]             128\n",
      "          Conv2d-243           [-1, 64, 56, 56]          36,864\n",
      "     BatchNorm2d-244           [-1, 64, 56, 56]             128\n",
      "      BasicBlock-245           [-1, 64, 56, 56]               0\n",
      "          Conv2d-246           [-1, 64, 56, 56]          36,864\n",
      "     BatchNorm2d-247           [-1, 64, 56, 56]             128\n",
      "          Conv2d-248           [-1, 64, 56, 56]          36,864\n",
      "     BatchNorm2d-249           [-1, 64, 56, 56]             128\n",
      "      BasicBlock-250           [-1, 64, 56, 56]               0\n",
      "          Conv2d-251           [-1, 64, 56, 56]          36,864\n",
      "     BatchNorm2d-252           [-1, 64, 56, 56]             128\n",
      "          Conv2d-253           [-1, 64, 56, 56]          36,864\n",
      "     BatchNorm2d-254           [-1, 64, 56, 56]             128\n",
      "      BasicBlock-255           [-1, 64, 56, 56]               0\n",
      "          Conv2d-256           [-1, 64, 56, 56]          36,864\n",
      "     BatchNorm2d-257           [-1, 64, 56, 56]             128\n",
      "          Conv2d-258           [-1, 64, 56, 56]          36,864\n",
      "     BatchNorm2d-259           [-1, 64, 56, 56]             128\n",
      "      BasicBlock-260           [-1, 64, 56, 56]               0\n",
      "          Conv2d-261           [-1, 64, 56, 56]          36,864\n",
      "     BatchNorm2d-262           [-1, 64, 56, 56]             128\n",
      "          Conv2d-263           [-1, 64, 56, 56]          36,864\n",
      "     BatchNorm2d-264           [-1, 64, 56, 56]             128\n",
      "      BasicBlock-265           [-1, 64, 56, 56]               0\n",
      "          Conv2d-266           [-1, 64, 56, 56]          36,864\n",
      "     BatchNorm2d-267           [-1, 64, 56, 56]             128\n",
      "          Conv2d-268           [-1, 64, 56, 56]          36,864\n",
      "     BatchNorm2d-269           [-1, 64, 56, 56]             128\n",
      "      BasicBlock-270           [-1, 64, 56, 56]               0\n",
      "          Conv2d-271           [-1, 64, 56, 56]          36,864\n",
      "     BatchNorm2d-272           [-1, 64, 56, 56]             128\n",
      "          Conv2d-273           [-1, 64, 56, 56]          36,864\n",
      "     BatchNorm2d-274           [-1, 64, 56, 56]             128\n",
      "      BasicBlock-275           [-1, 64, 56, 56]               0\n",
      "AdaptiveAvgPool2d-276             [-1, 64, 1, 1]               0\n",
      "          Linear-277                   [-1, 10]             650\n",
      "================================================================\n",
      "Total params: 1,727,962\n",
      "Trainable params: 1,727,962\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 987.66\n",
      "Params size (MB): 6.59\n",
      "Estimated Total Size (MB): 994.82\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(resnet110().cuda(), (3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Softwares\\Anaconda3\\envs\\test\\lib\\site-packages\\torch\\nn\\modules\\upsampling.py:122: UserWarning: nn.Upsampling is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.Upsampling is deprecated. Use nn.functional.interpolate instead.\")\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-43d300a2705a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moct_resnet110\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m224\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m224\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Softwares\\Anaconda3\\envs\\test\\lib\\site-packages\\torchsummary\\torchsummary.py\u001b[0m in \u001b[0;36msummary\u001b[1;34m(model, input_size, batch_size, device)\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[1;31m# make a forward pass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[1;31m# print(x.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[1;31m# remove these hooks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Softwares\\Anaconda3\\envs\\test\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 477\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    478\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\DL\\LiZeda\\InterestingProjects\\competition\\bd\\models\\oct_resnet.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    191\u001b[0m                 \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaxpool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 193\u001b[1;33m                 \u001b[0mx_h\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_l\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    194\u001b[0m                 \u001b[0mx_h\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_l\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_h\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx_l\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m                 \u001b[1;31m# x_h, x_l = self.layer3((x_h,x_l))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Softwares\\Anaconda3\\envs\\test\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 477\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    478\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Softwares\\Anaconda3\\envs\\test\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Softwares\\Anaconda3\\envs\\test\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 477\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    478\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\DL\\LiZeda\\InterestingProjects\\competition\\bd\\models\\oct_resnet.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m                 \u001b[0mx_h\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_l\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m                 \u001b[0mx_h\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_l\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_h\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_l\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m                 \u001b[0mx_h\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_l\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_h\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_l\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Softwares\\Anaconda3\\envs\\test\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 477\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    478\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\DL\\LiZeda\\InterestingProjects\\competition\\bd\\models\\octconv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m         \u001b[0mx_h\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_l\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m         \u001b[0mx_h\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mact\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbn_h\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_h\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m         \u001b[0mx_l\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mact\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbn_l\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_l\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx_l\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Softwares\\Anaconda3\\envs\\test\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    477\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    478\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 479\u001b[1;33m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    480\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhook_result\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m                 raise RuntimeError(\n",
      "\u001b[1;32mD:\\Softwares\\Anaconda3\\envs\\test\\lib\\site-packages\\torchsummary\\torchsummary.py\u001b[0m in \u001b[0;36mhook\u001b[1;34m(module, input, output)\u001b[0m\n\u001b[0;32m     17\u001b[0m             \u001b[0mm_key\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"%s-%i\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mclass_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodule_idx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m             \u001b[0msummary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mm_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m             \u001b[0msummary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mm_key\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"input_shape\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m             \u001b[0msummary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mm_key\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"input_shape\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "summary(oct_resnet110().cuda(), (3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pretrainedmodels import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu1): ReLU(inplace)\n",
       "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu2): ReLU(inplace)\n",
       "  (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       ")"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu1): ReLU(inplace)\n",
       "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu2): ReLU(inplace)\n",
       "  (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       ")"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer0_modules = [\n",
    "('conv1', nn.Conv2d(3, 64, 3, stride=2, padding=1,\n",
    "                    bias=False)),\n",
    "('bn1', nn.BatchNorm2d(64)),\n",
    "('relu1', nn.ReLU(inplace=True)),\n",
    "('conv2', nn.Conv2d(64, 64, 3, stride=1, padding=1,\n",
    "                    bias=False)),\n",
    "('bn2', nn.BatchNorm2d(64)),\n",
    "('relu2', nn.ReLU(inplace=True)),\n",
    "('conv3', nn.Conv2d(64, 64, 3, stride=1, padding=1,\n",
    "                    bias=False)),\n",
    "]\n",
    "\n",
    "nn.Sequential(OrderedDict(layer0_modules))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for SENet:\n\tMissing key(s) in state_dict: \"layer0.conv2.weight\", \"layer0.bn2.running_mean\", \"layer0.bn2.weight\", \"layer0.bn2.bias\", \"layer0.bn2.running_var\", \"layer0.conv3.weight\", \"layer0.bn3.running_mean\", \"layer0.bn3.weight\", \"layer0.bn3.bias\", \"layer0.bn3.running_var\". \n\tsize mismatch for layer0.conv1.weight: copying a param of torch.Size([64, 3, 3, 3]) from checkpoint, where the shape is torch.Size([64, 3, 7, 7]) in current model.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-4f26a7ef6c5c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mse50\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mse_resnext50_32x4d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_3x3\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mse50\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer0\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConv2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mse50\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mavg_pool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdaptiveAvgPool2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Softwares\\Anaconda3\\envs\\test\\lib\\site-packages\\pretrainedmodels\\models\\senet.py\u001b[0m in \u001b[0;36mse_resnext50_32x4d\u001b[1;34m(num_classes, pretrained, input_3x3)\u001b[0m\n\u001b[0;32m    428\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mpretrained\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    429\u001b[0m         \u001b[0msettings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpretrained_settings\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'se_resnext50_32x4d'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpretrained\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 430\u001b[1;33m         \u001b[0minitialize_pretrained_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msettings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    431\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    432\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Softwares\\Anaconda3\\envs\\test\\lib\\site-packages\\pretrainedmodels\\models\\senet.py\u001b[0m in \u001b[0;36minitialize_pretrained_model\u001b[1;34m(model, num_classes, settings)\u001b[0m\n\u001b[0;32m    371\u001b[0m         'num_classes should be {}, but is {}'.format(\n\u001b[0;32m    372\u001b[0m             settings['num_classes'], num_classes)\n\u001b[1;32m--> 373\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_zoo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_url\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'url'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    374\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_space\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msettings\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'input_space'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    375\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msettings\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'input_size'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Softwares\\Anaconda3\\envs\\test\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[1;34m(self, state_dict, strict)\u001b[0m\n\u001b[0;32m    717\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[1;32m--> 719\u001b[1;33m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[0;32m    720\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for SENet:\n\tMissing key(s) in state_dict: \"layer0.conv2.weight\", \"layer0.bn2.running_mean\", \"layer0.bn2.weight\", \"layer0.bn2.bias\", \"layer0.bn2.running_var\", \"layer0.conv3.weight\", \"layer0.bn3.running_mean\", \"layer0.bn3.weight\", \"layer0.bn3.bias\", \"layer0.bn3.running_var\". \n\tsize mismatch for layer0.conv1.weight: copying a param of torch.Size([64, 3, 3, 3]) from checkpoint, where the shape is torch.Size([64, 3, 7, 7]) in current model."
     ]
    }
   ],
   "source": [
    "se50 = models.se_resnext50_32x4d(input_3x3=True)\n",
    "se50.layer0.conv1 = nn.Conv2d(7, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
    "se50.avg_pool = nn.AdaptiveAvgPool2d(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 12, 13]           4,032\n",
      "       BatchNorm2d-2           [-1, 64, 12, 13]             128\n",
      "              ReLU-3           [-1, 64, 12, 13]               0\n",
      "            Conv2d-4           [-1, 64, 12, 13]          36,864\n",
      "       BatchNorm2d-5           [-1, 64, 12, 13]             128\n",
      "              ReLU-6           [-1, 64, 12, 13]               0\n",
      "            Conv2d-7           [-1, 64, 12, 13]          36,864\n",
      "       BatchNorm2d-8           [-1, 64, 12, 13]             128\n",
      "              ReLU-9           [-1, 64, 12, 13]               0\n",
      "        MaxPool2d-10             [-1, 64, 6, 6]               0\n",
      "           Conv2d-11            [-1, 128, 6, 6]           8,192\n",
      "      BatchNorm2d-12            [-1, 128, 6, 6]             256\n",
      "             ReLU-13            [-1, 128, 6, 6]               0\n",
      "           Conv2d-14            [-1, 128, 6, 6]           4,608\n",
      "      BatchNorm2d-15            [-1, 128, 6, 6]             256\n",
      "             ReLU-16            [-1, 128, 6, 6]               0\n",
      "           Conv2d-17            [-1, 256, 6, 6]          32,768\n",
      "      BatchNorm2d-18            [-1, 256, 6, 6]             512\n",
      "           Conv2d-19            [-1, 256, 6, 6]          16,384\n",
      "      BatchNorm2d-20            [-1, 256, 6, 6]             512\n",
      "AdaptiveAvgPool2d-21            [-1, 256, 1, 1]               0\n",
      "           Conv2d-22             [-1, 16, 1, 1]           4,112\n",
      "             ReLU-23             [-1, 16, 1, 1]               0\n",
      "           Conv2d-24            [-1, 256, 1, 1]           4,352\n",
      "          Sigmoid-25            [-1, 256, 1, 1]               0\n",
      "         SEModule-26            [-1, 256, 6, 6]               0\n",
      "             ReLU-27            [-1, 256, 6, 6]               0\n",
      "SEResNeXtBottleneck-28            [-1, 256, 6, 6]               0\n",
      "           Conv2d-29            [-1, 128, 6, 6]          32,768\n",
      "      BatchNorm2d-30            [-1, 128, 6, 6]             256\n",
      "             ReLU-31            [-1, 128, 6, 6]               0\n",
      "           Conv2d-32            [-1, 128, 6, 6]           4,608\n",
      "      BatchNorm2d-33            [-1, 128, 6, 6]             256\n",
      "             ReLU-34            [-1, 128, 6, 6]               0\n",
      "           Conv2d-35            [-1, 256, 6, 6]          32,768\n",
      "      BatchNorm2d-36            [-1, 256, 6, 6]             512\n",
      "AdaptiveAvgPool2d-37            [-1, 256, 1, 1]               0\n",
      "           Conv2d-38             [-1, 16, 1, 1]           4,112\n",
      "             ReLU-39             [-1, 16, 1, 1]               0\n",
      "           Conv2d-40            [-1, 256, 1, 1]           4,352\n",
      "          Sigmoid-41            [-1, 256, 1, 1]               0\n",
      "         SEModule-42            [-1, 256, 6, 6]               0\n",
      "             ReLU-43            [-1, 256, 6, 6]               0\n",
      "SEResNeXtBottleneck-44            [-1, 256, 6, 6]               0\n",
      "           Conv2d-45            [-1, 128, 6, 6]          32,768\n",
      "      BatchNorm2d-46            [-1, 128, 6, 6]             256\n",
      "             ReLU-47            [-1, 128, 6, 6]               0\n",
      "           Conv2d-48            [-1, 128, 6, 6]           4,608\n",
      "      BatchNorm2d-49            [-1, 128, 6, 6]             256\n",
      "             ReLU-50            [-1, 128, 6, 6]               0\n",
      "           Conv2d-51            [-1, 256, 6, 6]          32,768\n",
      "      BatchNorm2d-52            [-1, 256, 6, 6]             512\n",
      "AdaptiveAvgPool2d-53            [-1, 256, 1, 1]               0\n",
      "           Conv2d-54             [-1, 16, 1, 1]           4,112\n",
      "             ReLU-55             [-1, 16, 1, 1]               0\n",
      "           Conv2d-56            [-1, 256, 1, 1]           4,352\n",
      "          Sigmoid-57            [-1, 256, 1, 1]               0\n",
      "         SEModule-58            [-1, 256, 6, 6]               0\n",
      "             ReLU-59            [-1, 256, 6, 6]               0\n",
      "SEResNeXtBottleneck-60            [-1, 256, 6, 6]               0\n",
      "           Conv2d-61            [-1, 256, 6, 6]          65,536\n",
      "      BatchNorm2d-62            [-1, 256, 6, 6]             512\n",
      "             ReLU-63            [-1, 256, 6, 6]               0\n",
      "           Conv2d-64            [-1, 256, 3, 3]          18,432\n",
      "      BatchNorm2d-65            [-1, 256, 3, 3]             512\n",
      "             ReLU-66            [-1, 256, 3, 3]               0\n",
      "           Conv2d-67            [-1, 512, 3, 3]         131,072\n",
      "      BatchNorm2d-68            [-1, 512, 3, 3]           1,024\n",
      "           Conv2d-69            [-1, 512, 3, 3]         131,072\n",
      "      BatchNorm2d-70            [-1, 512, 3, 3]           1,024\n",
      "AdaptiveAvgPool2d-71            [-1, 512, 1, 1]               0\n",
      "           Conv2d-72             [-1, 32, 1, 1]          16,416\n",
      "             ReLU-73             [-1, 32, 1, 1]               0\n",
      "           Conv2d-74            [-1, 512, 1, 1]          16,896\n",
      "          Sigmoid-75            [-1, 512, 1, 1]               0\n",
      "         SEModule-76            [-1, 512, 3, 3]               0\n",
      "             ReLU-77            [-1, 512, 3, 3]               0\n",
      "SEResNeXtBottleneck-78            [-1, 512, 3, 3]               0\n",
      "           Conv2d-79            [-1, 256, 3, 3]         131,072\n",
      "      BatchNorm2d-80            [-1, 256, 3, 3]             512\n",
      "             ReLU-81            [-1, 256, 3, 3]               0\n",
      "           Conv2d-82            [-1, 256, 3, 3]          18,432\n",
      "      BatchNorm2d-83            [-1, 256, 3, 3]             512\n",
      "             ReLU-84            [-1, 256, 3, 3]               0\n",
      "           Conv2d-85            [-1, 512, 3, 3]         131,072\n",
      "      BatchNorm2d-86            [-1, 512, 3, 3]           1,024\n",
      "AdaptiveAvgPool2d-87            [-1, 512, 1, 1]               0\n",
      "           Conv2d-88             [-1, 32, 1, 1]          16,416\n",
      "             ReLU-89             [-1, 32, 1, 1]               0\n",
      "           Conv2d-90            [-1, 512, 1, 1]          16,896\n",
      "          Sigmoid-91            [-1, 512, 1, 1]               0\n",
      "         SEModule-92            [-1, 512, 3, 3]               0\n",
      "             ReLU-93            [-1, 512, 3, 3]               0\n",
      "SEResNeXtBottleneck-94            [-1, 512, 3, 3]               0\n",
      "           Conv2d-95            [-1, 256, 3, 3]         131,072\n",
      "      BatchNorm2d-96            [-1, 256, 3, 3]             512\n",
      "             ReLU-97            [-1, 256, 3, 3]               0\n",
      "           Conv2d-98            [-1, 256, 3, 3]          18,432\n",
      "      BatchNorm2d-99            [-1, 256, 3, 3]             512\n",
      "            ReLU-100            [-1, 256, 3, 3]               0\n",
      "          Conv2d-101            [-1, 512, 3, 3]         131,072\n",
      "     BatchNorm2d-102            [-1, 512, 3, 3]           1,024\n",
      "AdaptiveAvgPool2d-103            [-1, 512, 1, 1]               0\n",
      "          Conv2d-104             [-1, 32, 1, 1]          16,416\n",
      "            ReLU-105             [-1, 32, 1, 1]               0\n",
      "          Conv2d-106            [-1, 512, 1, 1]          16,896\n",
      "         Sigmoid-107            [-1, 512, 1, 1]               0\n",
      "        SEModule-108            [-1, 512, 3, 3]               0\n",
      "            ReLU-109            [-1, 512, 3, 3]               0\n",
      "SEResNeXtBottleneck-110            [-1, 512, 3, 3]               0\n",
      "          Conv2d-111            [-1, 256, 3, 3]         131,072\n",
      "     BatchNorm2d-112            [-1, 256, 3, 3]             512\n",
      "            ReLU-113            [-1, 256, 3, 3]               0\n",
      "          Conv2d-114            [-1, 256, 3, 3]          18,432\n",
      "     BatchNorm2d-115            [-1, 256, 3, 3]             512\n",
      "            ReLU-116            [-1, 256, 3, 3]               0\n",
      "          Conv2d-117            [-1, 512, 3, 3]         131,072\n",
      "     BatchNorm2d-118            [-1, 512, 3, 3]           1,024\n",
      "AdaptiveAvgPool2d-119            [-1, 512, 1, 1]               0\n",
      "          Conv2d-120             [-1, 32, 1, 1]          16,416\n",
      "            ReLU-121             [-1, 32, 1, 1]               0\n",
      "          Conv2d-122            [-1, 512, 1, 1]          16,896\n",
      "         Sigmoid-123            [-1, 512, 1, 1]               0\n",
      "        SEModule-124            [-1, 512, 3, 3]               0\n",
      "            ReLU-125            [-1, 512, 3, 3]               0\n",
      "SEResNeXtBottleneck-126            [-1, 512, 3, 3]               0\n",
      "          Conv2d-127            [-1, 512, 3, 3]         262,144\n",
      "     BatchNorm2d-128            [-1, 512, 3, 3]           1,024\n",
      "            ReLU-129            [-1, 512, 3, 3]               0\n",
      "          Conv2d-130            [-1, 512, 2, 2]          73,728\n",
      "     BatchNorm2d-131            [-1, 512, 2, 2]           1,024\n",
      "            ReLU-132            [-1, 512, 2, 2]               0\n",
      "          Conv2d-133           [-1, 1024, 2, 2]         524,288\n",
      "     BatchNorm2d-134           [-1, 1024, 2, 2]           2,048\n",
      "          Conv2d-135           [-1, 1024, 2, 2]         524,288\n",
      "     BatchNorm2d-136           [-1, 1024, 2, 2]           2,048\n",
      "AdaptiveAvgPool2d-137           [-1, 1024, 1, 1]               0\n",
      "          Conv2d-138             [-1, 64, 1, 1]          65,600\n",
      "            ReLU-139             [-1, 64, 1, 1]               0\n",
      "          Conv2d-140           [-1, 1024, 1, 1]          66,560\n",
      "         Sigmoid-141           [-1, 1024, 1, 1]               0\n",
      "        SEModule-142           [-1, 1024, 2, 2]               0\n",
      "            ReLU-143           [-1, 1024, 2, 2]               0\n",
      "SEResNeXtBottleneck-144           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-145            [-1, 512, 2, 2]         524,288\n",
      "     BatchNorm2d-146            [-1, 512, 2, 2]           1,024\n",
      "            ReLU-147            [-1, 512, 2, 2]               0\n",
      "          Conv2d-148            [-1, 512, 2, 2]          73,728\n",
      "     BatchNorm2d-149            [-1, 512, 2, 2]           1,024\n",
      "            ReLU-150            [-1, 512, 2, 2]               0\n",
      "          Conv2d-151           [-1, 1024, 2, 2]         524,288\n",
      "     BatchNorm2d-152           [-1, 1024, 2, 2]           2,048\n",
      "AdaptiveAvgPool2d-153           [-1, 1024, 1, 1]               0\n",
      "          Conv2d-154             [-1, 64, 1, 1]          65,600\n",
      "            ReLU-155             [-1, 64, 1, 1]               0\n",
      "          Conv2d-156           [-1, 1024, 1, 1]          66,560\n",
      "         Sigmoid-157           [-1, 1024, 1, 1]               0\n",
      "        SEModule-158           [-1, 1024, 2, 2]               0\n",
      "            ReLU-159           [-1, 1024, 2, 2]               0\n",
      "SEResNeXtBottleneck-160           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-161            [-1, 512, 2, 2]         524,288\n",
      "     BatchNorm2d-162            [-1, 512, 2, 2]           1,024\n",
      "            ReLU-163            [-1, 512, 2, 2]               0\n",
      "          Conv2d-164            [-1, 512, 2, 2]          73,728\n",
      "     BatchNorm2d-165            [-1, 512, 2, 2]           1,024\n",
      "            ReLU-166            [-1, 512, 2, 2]               0\n",
      "          Conv2d-167           [-1, 1024, 2, 2]         524,288\n",
      "     BatchNorm2d-168           [-1, 1024, 2, 2]           2,048\n",
      "AdaptiveAvgPool2d-169           [-1, 1024, 1, 1]               0\n",
      "          Conv2d-170             [-1, 64, 1, 1]          65,600\n",
      "            ReLU-171             [-1, 64, 1, 1]               0\n",
      "          Conv2d-172           [-1, 1024, 1, 1]          66,560\n",
      "         Sigmoid-173           [-1, 1024, 1, 1]               0\n",
      "        SEModule-174           [-1, 1024, 2, 2]               0\n",
      "            ReLU-175           [-1, 1024, 2, 2]               0\n",
      "SEResNeXtBottleneck-176           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-177            [-1, 512, 2, 2]         524,288\n",
      "     BatchNorm2d-178            [-1, 512, 2, 2]           1,024\n",
      "            ReLU-179            [-1, 512, 2, 2]               0\n",
      "          Conv2d-180            [-1, 512, 2, 2]          73,728\n",
      "     BatchNorm2d-181            [-1, 512, 2, 2]           1,024\n",
      "            ReLU-182            [-1, 512, 2, 2]               0\n",
      "          Conv2d-183           [-1, 1024, 2, 2]         524,288\n",
      "     BatchNorm2d-184           [-1, 1024, 2, 2]           2,048\n",
      "AdaptiveAvgPool2d-185           [-1, 1024, 1, 1]               0\n",
      "          Conv2d-186             [-1, 64, 1, 1]          65,600\n",
      "            ReLU-187             [-1, 64, 1, 1]               0\n",
      "          Conv2d-188           [-1, 1024, 1, 1]          66,560\n",
      "         Sigmoid-189           [-1, 1024, 1, 1]               0\n",
      "        SEModule-190           [-1, 1024, 2, 2]               0\n",
      "            ReLU-191           [-1, 1024, 2, 2]               0\n",
      "SEResNeXtBottleneck-192           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-193            [-1, 512, 2, 2]         524,288\n",
      "     BatchNorm2d-194            [-1, 512, 2, 2]           1,024\n",
      "            ReLU-195            [-1, 512, 2, 2]               0\n",
      "          Conv2d-196            [-1, 512, 2, 2]          73,728\n",
      "     BatchNorm2d-197            [-1, 512, 2, 2]           1,024\n",
      "            ReLU-198            [-1, 512, 2, 2]               0\n",
      "          Conv2d-199           [-1, 1024, 2, 2]         524,288\n",
      "     BatchNorm2d-200           [-1, 1024, 2, 2]           2,048\n",
      "AdaptiveAvgPool2d-201           [-1, 1024, 1, 1]               0\n",
      "          Conv2d-202             [-1, 64, 1, 1]          65,600\n",
      "            ReLU-203             [-1, 64, 1, 1]               0\n",
      "          Conv2d-204           [-1, 1024, 1, 1]          66,560\n",
      "         Sigmoid-205           [-1, 1024, 1, 1]               0\n",
      "        SEModule-206           [-1, 1024, 2, 2]               0\n",
      "            ReLU-207           [-1, 1024, 2, 2]               0\n",
      "SEResNeXtBottleneck-208           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-209            [-1, 512, 2, 2]         524,288\n",
      "     BatchNorm2d-210            [-1, 512, 2, 2]           1,024\n",
      "            ReLU-211            [-1, 512, 2, 2]               0\n",
      "          Conv2d-212            [-1, 512, 2, 2]          73,728\n",
      "     BatchNorm2d-213            [-1, 512, 2, 2]           1,024\n",
      "            ReLU-214            [-1, 512, 2, 2]               0\n",
      "          Conv2d-215           [-1, 1024, 2, 2]         524,288\n",
      "     BatchNorm2d-216           [-1, 1024, 2, 2]           2,048\n",
      "AdaptiveAvgPool2d-217           [-1, 1024, 1, 1]               0\n",
      "          Conv2d-218             [-1, 64, 1, 1]          65,600\n",
      "            ReLU-219             [-1, 64, 1, 1]               0\n",
      "          Conv2d-220           [-1, 1024, 1, 1]          66,560\n",
      "         Sigmoid-221           [-1, 1024, 1, 1]               0\n",
      "        SEModule-222           [-1, 1024, 2, 2]               0\n",
      "            ReLU-223           [-1, 1024, 2, 2]               0\n",
      "SEResNeXtBottleneck-224           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-225           [-1, 1024, 2, 2]       1,048,576\n",
      "     BatchNorm2d-226           [-1, 1024, 2, 2]           2,048\n",
      "            ReLU-227           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-228           [-1, 1024, 1, 1]         294,912\n",
      "     BatchNorm2d-229           [-1, 1024, 1, 1]           2,048\n",
      "            ReLU-230           [-1, 1024, 1, 1]               0\n",
      "          Conv2d-231           [-1, 2048, 1, 1]       2,097,152\n",
      "     BatchNorm2d-232           [-1, 2048, 1, 1]           4,096\n",
      "          Conv2d-233           [-1, 2048, 1, 1]       2,097,152\n",
      "     BatchNorm2d-234           [-1, 2048, 1, 1]           4,096\n",
      "AdaptiveAvgPool2d-235           [-1, 2048, 1, 1]               0\n",
      "          Conv2d-236            [-1, 128, 1, 1]         262,272\n",
      "            ReLU-237            [-1, 128, 1, 1]               0\n",
      "          Conv2d-238           [-1, 2048, 1, 1]         264,192\n",
      "         Sigmoid-239           [-1, 2048, 1, 1]               0\n",
      "        SEModule-240           [-1, 2048, 1, 1]               0\n",
      "            ReLU-241           [-1, 2048, 1, 1]               0\n",
      "SEResNeXtBottleneck-242           [-1, 2048, 1, 1]               0\n",
      "          Conv2d-243           [-1, 1024, 1, 1]       2,097,152\n",
      "     BatchNorm2d-244           [-1, 1024, 1, 1]           2,048\n",
      "            ReLU-245           [-1, 1024, 1, 1]               0\n",
      "          Conv2d-246           [-1, 1024, 1, 1]         294,912\n",
      "     BatchNorm2d-247           [-1, 1024, 1, 1]           2,048\n",
      "            ReLU-248           [-1, 1024, 1, 1]               0\n",
      "          Conv2d-249           [-1, 2048, 1, 1]       2,097,152\n",
      "     BatchNorm2d-250           [-1, 2048, 1, 1]           4,096\n",
      "AdaptiveAvgPool2d-251           [-1, 2048, 1, 1]               0\n",
      "          Conv2d-252            [-1, 128, 1, 1]         262,272\n",
      "            ReLU-253            [-1, 128, 1, 1]               0\n",
      "          Conv2d-254           [-1, 2048, 1, 1]         264,192\n",
      "         Sigmoid-255           [-1, 2048, 1, 1]               0\n",
      "        SEModule-256           [-1, 2048, 1, 1]               0\n",
      "            ReLU-257           [-1, 2048, 1, 1]               0\n",
      "SEResNeXtBottleneck-258           [-1, 2048, 1, 1]               0\n",
      "          Conv2d-259           [-1, 1024, 1, 1]       2,097,152\n",
      "     BatchNorm2d-260           [-1, 1024, 1, 1]           2,048\n",
      "            ReLU-261           [-1, 1024, 1, 1]               0\n",
      "          Conv2d-262           [-1, 1024, 1, 1]         294,912\n",
      "     BatchNorm2d-263           [-1, 1024, 1, 1]           2,048\n",
      "            ReLU-264           [-1, 1024, 1, 1]               0\n",
      "          Conv2d-265           [-1, 2048, 1, 1]       2,097,152\n",
      "     BatchNorm2d-266           [-1, 2048, 1, 1]           4,096\n",
      "AdaptiveAvgPool2d-267           [-1, 2048, 1, 1]               0\n",
      "          Conv2d-268            [-1, 128, 1, 1]         262,272\n",
      "            ReLU-269            [-1, 128, 1, 1]               0\n",
      "          Conv2d-270           [-1, 2048, 1, 1]         264,192\n",
      "         Sigmoid-271           [-1, 2048, 1, 1]               0\n",
      "        SEModule-272           [-1, 2048, 1, 1]               0\n",
      "            ReLU-273           [-1, 2048, 1, 1]               0\n",
      "SEResNeXtBottleneck-274           [-1, 2048, 1, 1]               0\n",
      "AdaptiveAvgPool2d-275           [-1, 2048, 1, 1]               0\n",
      "          Linear-276                 [-1, 1000]       2,049,000\n",
      "================================================================\n",
      "Total params: 27,628,504\n",
      "Trainable params: 27,628,504\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.02\n",
      "Forward/backward pass size (MB): 6.37\n",
      "Params size (MB): 105.39\n",
      "Estimated Total Size (MB): 111.78\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(se50.cuda(), (7, 24, 26))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = np.arange(10).reshape(2, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2, 3, 4],\n",
       "       [5, 6, 7, 8, 9]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.14285714, 0.22222222, 0.27272727, 0.30769231],\n",
       "       [1.        , 0.85714286, 0.77777778, 0.72727273, 0.69230769]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X / np.sum(X, 0, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:test]",
   "language": "python",
   "name": "conda-env-test-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
